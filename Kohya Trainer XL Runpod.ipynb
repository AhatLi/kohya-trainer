{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d61cd191-c05c-4fdf-abf9-d8fc2e899679",
   "metadata": {},
   "source": [
    "# KOHYA TRAINER XL "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57fd336-eac2-4917-ad00-b0ae7ca92467",
   "metadata": {},
   "source": [
    "# Install Kohya Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47275565-07d5-42a2-aee0-1500ef509fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "streamlit 1.24.1 requires pillow<10,>=6.2.0, but you have pillow 10.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m27 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
      "aria2 is already the newest version (1.36.0-1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 27 not upgraded.\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "\n",
    "# root_dir\n",
    "root_dir          = \"/workspace\"\n",
    "drive_dir         = os.path.join(root_dir, \"drive\", \"MyDrive\")\n",
    "deps_dir          = os.path.join(root_dir, \"deps\")\n",
    "repo_dir          = os.path.join(root_dir, \"kohya-trainer\")\n",
    "training_dir      = os.path.join(root_dir, \"fine_tune\")\n",
    "pretrained_model  = os.path.join(root_dir, \"pretrained_model\")\n",
    "vae_dir           = os.path.join(root_dir, \"vae\")\n",
    "lora_dir          = os.path.join(root_dir, \"network_weight\")\n",
    "config_dir        = os.path.join(training_dir, \"config\")\n",
    "output_dir        = os.path.join(training_dir, \"outputs\")\n",
    "tools_dir         = os.path.join(repo_dir, \"tools\")\n",
    "finetune_dir      = os.path.join(repo_dir, \"finetune\")\n",
    "accelerate_config = os.path.join(repo_dir, \"accelerate_config\", \"config.yaml\")\n",
    "\n",
    "repo_url          = \"https://github.com/qaneel/kohya-trainer\"\n",
    "branch            = \"main\" \n",
    "\n",
    "def clone_repo(url, dir, branch):\n",
    "    if not os.path.exists(dir):\n",
    "       !git clone -b {branch} {url} {dir}\n",
    "\n",
    "def install_dependencies():\n",
    "    !apt update -yqq\n",
    "    !apt install aria2 -yqq\n",
    "    !pip install -q --upgrade -r requirements.txt\n",
    "    !pip install xformers\n",
    "\n",
    "    from accelerate.utils import write_basic_config\n",
    "\n",
    "    if not os.path.exists(accelerate_config):\n",
    "        write_basic_config(save_location=accelerate_config)\n",
    "\n",
    "def prepare_environment():\n",
    "    os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "    os.environ[\"SAFETENSORS_FAST_GPU\"] = \"1\"\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "\n",
    "def main():\n",
    "    os.chdir(root_dir)\n",
    "    clone_repo(repo_url, repo_dir, branch)\n",
    "    os.chdir(repo_dir)\n",
    "    for dir in [training_dir, config_dir, pretrained_model, vae_dir, repositories_dir, output_dir]:\n",
    "        os.makedirs(dir, exist_ok=True)\n",
    "    install_dependencies()\n",
    "    prepare_environment()\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29066e0b-e268-4b58-9ea4-3893bbe516fe",
   "metadata": {},
   "source": [
    "# Download SDXL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d1c8656-4323-4813-a785-6cee93bac903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[#9c1cff 0B/12GiB(0%) CN:1 DL:0B] [FileAlloc:#9c1cff 344MiB/12GiB(2%)]\n",
      "[#9c1cff 0B/12GiB(0%) CN:1 DL:0B] [FileAlloc:#9c1cff 854MiB/12GiB(6%)]\n",
      "[#9c1cff 0B/12GiB(0%) CN:1 DL:0B] [FileAlloc:#9c1cff 1.2GiB/12GiB(9%)]\n",
      "[#9c1cff 0B/12GiB(0%) CN:1 DL:0B] [FileAlloc:#9c1cff 1.7GiB/12GiB(13%)]\n",
      "[#9c1cff 0B/12GiB(0%) CN:1 DL:0B] [FileAlloc:#9c1cff 2.1GiB/12GiB(16%)]\n",
      "[#9c1cff 0B/12GiB(0%) CN:1 DL:0B] [FileAlloc:#9c1cff 2.5GiB/12GiB(19%)]\n",
      "[#9c1cff 0B/12GiB(0%) CN:1 DL:0B] [FileAlloc:#9c1cff 2.9GiB/12GiB(23%)]\n",
      "[#9c1cff 0B/12GiB(0%) CN:1 DL:0B] [FileAlloc:#9c1cff 3.3GiB/12GiB(26%)]\n",
      "[#9c1cff 0B/12GiB(0%) CN:1 DL:0B] [FileAlloc:#9c1cff 3.8GiB/12GiB(29%)]\n",
      "[#9c1cff 0B/12GiB(0%) CN:1 DL:0B] [FileAlloc:#9c1cff 4.2GiB/12GiB(33%)]\n",
      " *** Download Progress Summary as of Sun Jul  9 07:15:47 2023 *** \n",
      "===============================================================================\n",
      "[#9c1cff 0B/12GiB(0%) CN:1 DL:0B]\n",
      "FILE: /workspace/pretrained_model/sd_xl_base_0.9.safetensors\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "[#9c1cff 0B/12GiB(0%) CN:1 DL:0B] [FileAlloc:#9c1cff 4.6GiB/12GiB(36%)]\n",
      "[#9c1cff 0B/12GiB(0%) CN:1 DL:0B] [FileAlloc:#9c1cff 5.0GiB/12GiB(39%)]\n",
      "[#9c1cff 0B/12GiB(0%) CN:1 DL:0B] [FileAlloc:#9c1cff 5.4GiB/12GiB(42%)]\n",
      "[#9c1cff 0B/12GiB(0%) CN:1 DL:0B] [FileAlloc:#9c1cff 5.8GiB/12GiB(45%)]\n",
      "[#9c1cff 0B/12GiB(0%) CN:1 DL:0B] [FileAlloc:#9c1cff 6.2GiB/12GiB(48%)]\n",
      "[#9c1cff 0B/12GiB(0%) CN:1 DL:0B] [FileAlloc:#9c1cff 6.6GiB/12GiB(51%)]\n",
      "[#9c1cff 0B/12GiB(0%) CN:1 DL:0B] [FileAlloc:#9c1cff 7.1GiB/12GiB(55%)]\n",
      "[#9c1cff 0B/12GiB(0%) CN:1 DL:0B] [FileAlloc:#9c1cff 7.6GiB/12GiB(58%)]\n",
      "[#9c1cff 0B/12GiB(0%) CN:1 DL:0B] [FileAlloc:#9c1cff 8.0GiB/12GiB(62%)]\n",
      "[#9c1cff 0B/12GiB(0%) CN:1 DL:0B] [FileAlloc:#9c1cff 8.4GiB/12GiB(65%)]\n",
      "[#9c1cff 0B/12GiB(0%) CN:1 DL:0B] [FileAlloc:#9c1cff 8.8GiB/12GiB(68%)]\n",
      " *** Download Progress Summary as of Sun Jul  9 07:15:58 2023 *** \n",
      "===============================================================================\n",
      "[#9c1cff 0B/12GiB(0%) CN:1 DL:0B]\n",
      "FILE: /workspace/pretrained_model/sd_xl_base_0.9.safetensors\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "[#9c1cff 0B/12GiB(0%) CN:1 DL:0B] [FileAlloc:#9c1cff 9.2GiB/12GiB(71%)]\n",
      "[#9c1cff 0B/12GiB(0%) CN:1 DL:0B] [FileAlloc:#9c1cff 9.6GiB/12GiB(74%)]\n",
      "[#9c1cff 0B/12GiB(0%) CN:1 DL:0B] [FileAlloc:#9c1cff 10GiB/12GiB(77%)]\n",
      "[#9c1cff 0B/12GiB(0%) CN:1 DL:0B] [FileAlloc:#9c1cff 10GiB/12GiB(80%)]\n",
      "[#9c1cff 0B/12GiB(0%) CN:1 DL:0B] [FileAlloc:#9c1cff 10GiB/12GiB(83%)]\n",
      "[#9c1cff 0B/12GiB(0%) CN:1 DL:0B] [FileAlloc:#9c1cff 11GiB/12GiB(86%)]\n",
      "[#9c1cff 0B/12GiB(0%) CN:1 DL:0B] [FileAlloc:#9c1cff 11GiB/12GiB(90%)]\n",
      "[#9c1cff 0B/12GiB(0%) CN:1 DL:0B] [FileAlloc:#9c1cff 12GiB/12GiB(93%)]\n",
      "[#9c1cff 0B/12GiB(0%) CN:1 DL:0B] [FileAlloc:#9c1cff 12GiB/12GiB(96%)]\n",
      " *** Download Progress Summary as of Sun Jul  9 07:16:09 2023 *** \n",
      "===============================================================================\n",
      "[#9c1cff 0B/12GiB(0%) CN:1 DL:0B]\n",
      "FILE: /workspace/pretrained_model/sd_xl_base_0.9.safetensors\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "[#9c1cff 0B/12GiB(0%) CN:1 DL:0B]\n",
      "[#9c1cff 63MiB/12GiB(0%) CN:16 DL:64MiB ETA:3m24s]\n",
      "[#9c1cff 143MiB/12GiB(1%) CN:16 DL:72MiB ETA:3m1s]\n",
      "[#9c1cff 225MiB/12GiB(1%) CN:16 DL:75MiB ETA:2m52s]\n",
      "[#9c1cff 307MiB/12GiB(2%) CN:16 DL:77MiB ETA:2m47s]\n",
      "[#9c1cff 387MiB/12GiB(2%) CN:16 DL:77MiB ETA:2m45s]\n",
      "[#9c1cff 468MiB/12GiB(3%) CN:16 DL:78MiB ETA:2m42s]\n",
      "[#9c1cff 549MiB/12GiB(4%) CN:16 DL:78MiB ETA:2m41s]\n",
      "[#9c1cff 628MiB/12GiB(4%) CN:16 DL:78MiB ETA:2m39s]\n",
      "[#9c1cff 706MiB/12GiB(5%) CN:16 DL:78MiB ETA:2m39s]\n",
      "[#9c1cff 783MiB/12GiB(5%) CN:16 DL:78MiB ETA:2m38s]\n",
      " *** Download Progress Summary as of Sun Jul  9 07:16:20 2023 *** \n",
      "===============================================================================\n",
      "[#9c1cff 862MiB/12GiB(6%) CN:16 DL:80MiB ETA:2m34s]\n",
      "FILE: /workspace/pretrained_model/sd_xl_base_0.9.safetensors\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "[#9c1cff 862MiB/12GiB(6%) CN:16 DL:80MiB ETA:2m34s]\n",
      "[#9c1cff 0.9GiB/12GiB(7%) CN:16 DL:79MiB ETA:2m34s]\n",
      "[#9c1cff 0.9GiB/12GiB(7%) CN:16 DL:78MiB ETA:2m34s]\n",
      "[#9c1cff 1.0GiB/12GiB(8%) CN:16 DL:78MiB ETA:2m35s]\n",
      "[#9c1cff 1.1GiB/12GiB(8%) CN:16 DL:77MiB ETA:2m35s]\n",
      "[#9c1cff 1.2GiB/12GiB(9%) CN:16 DL:76MiB ETA:2m36s]\n",
      "[#9c1cff 1.2GiB/12GiB(9%) CN:16 DL:76MiB ETA:2m35s]\n",
      "[#9c1cff 1.3GiB/12GiB(10%) CN:16 DL:76MiB ETA:2m34s]\n",
      "[#9c1cff 1.4GiB/12GiB(11%) CN:16 DL:76MiB ETA:2m33s]\n",
      "[#9c1cff 1.5GiB/12GiB(11%) CN:16 DL:77MiB ETA:2m31s]\n",
      "[#9c1cff 1.5GiB/12GiB(12%) CN:16 DL:77MiB ETA:2m29s]\n",
      " *** Download Progress Summary as of Sun Jul  9 07:16:31 2023 *** \n",
      "===============================================================================\n",
      "[#9c1cff 1.6GiB/12GiB(12%) CN:16 DL:77MiB ETA:2m28s]\n",
      "FILE: /workspace/pretrained_model/sd_xl_base_0.9.safetensors\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "[#9c1cff 1.6GiB/12GiB(12%) CN:16 DL:77MiB ETA:2m28s]\n",
      "[#9c1cff 1.7GiB/12GiB(13%) CN:16 DL:78MiB ETA:2m26s]\n",
      "[#9c1cff 1.8GiB/12GiB(14%) CN:16 DL:78MiB ETA:2m24s]\n",
      "[#9c1cff 1.8GiB/12GiB(14%) CN:16 DL:78MiB ETA:2m22s]\n",
      "[#9c1cff 1.9GiB/12GiB(15%) CN:16 DL:78MiB ETA:2m22s]\n",
      "[#9c1cff 2.0GiB/12GiB(15%) CN:16 DL:78MiB ETA:2m22s]\n",
      "[#9c1cff 2.1GiB/12GiB(16%) CN:16 DL:78MiB ETA:2m20s]\n",
      "[#9c1cff 2.2GiB/12GiB(17%) CN:16 DL:78MiB ETA:2m19s]\n",
      "[#9c1cff 2.2GiB/12GiB(17%) CN:16 DL:79MiB ETA:2m16s]\n",
      "[#9c1cff 2.3GiB/12GiB(18%) CN:16 DL:78MiB ETA:2m17s]\n",
      "[#9c1cff 2.4GiB/12GiB(18%) CN:16 DL:78MiB ETA:2m16s]\n",
      " *** Download Progress Summary as of Sun Jul  9 07:16:42 2023 *** \n",
      "===============================================================================\n",
      "[#9c1cff 2.5GiB/12GiB(19%) CN:16 DL:78MiB ETA:2m15s]\n",
      "FILE: /workspace/pretrained_model/sd_xl_base_0.9.safetensors\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "[#9c1cff 2.5GiB/12GiB(19%) CN:16 DL:78MiB ETA:2m15s]\n",
      "[#9c1cff 2.5GiB/12GiB(20%) CN:16 DL:79MiB ETA:2m13s]\n",
      "[#9c1cff 2.6GiB/12GiB(20%) CN:16 DL:79MiB ETA:2m12s]\n",
      "[#9c1cff 2.7GiB/12GiB(21%) CN:16 DL:79MiB ETA:2m11s]\n",
      "[#9c1cff 2.8GiB/12GiB(21%) CN:16 DL:79MiB ETA:2m10s]\n",
      "[#9c1cff 2.8GiB/12GiB(22%) CN:16 DL:78MiB ETA:2m10s]\n",
      "[#9c1cff 2.9GiB/12GiB(22%) CN:16 DL:78MiB ETA:2m10s]\n",
      "[#9c1cff 3.0GiB/12GiB(23%) CN:16 DL:77MiB ETA:2m10s]\n",
      "[#9c1cff 3.1GiB/12GiB(24%) CN:16 DL:78MiB ETA:2m8s]\n",
      "[#9c1cff 3.2GiB/12GiB(24%) CN:16 DL:79MiB ETA:2m5s]\n",
      "[#9c1cff 3.2GiB/12GiB(25%) CN:16 DL:79MiB ETA:2m4s]\n",
      " *** Download Progress Summary as of Sun Jul  9 07:16:52 2023 *** \n",
      "===============================================================================\n",
      "[#9c1cff 3.3GiB/12GiB(26%) CN:16 DL:79MiB ETA:2m3s]\n",
      "FILE: /workspace/pretrained_model/sd_xl_base_0.9.safetensors\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "[#9c1cff 3.3GiB/12GiB(26%) CN:16 DL:79MiB ETA:2m3s]\n",
      "[#9c1cff 3.4GiB/12GiB(26%) CN:16 DL:78MiB ETA:2m3s]\n",
      "[#9c1cff 3.5GiB/12GiB(27%) CN:16 DL:78MiB ETA:2m3s]\n",
      "[#9c1cff 3.5GiB/12GiB(27%) CN:16 DL:77MiB ETA:2m3s]\n",
      "[#9c1cff 3.6GiB/12GiB(28%) CN:16 DL:77MiB ETA:2m2s]\n",
      "[#9c1cff 3.7GiB/12GiB(28%) CN:16 DL:77MiB ETA:2m2s]\n",
      "[#9c1cff 3.7GiB/12GiB(29%) CN:16 DL:77MiB ETA:2m]\n",
      "[#9c1cff 3.8GiB/12GiB(29%) CN:16 DL:75MiB ETA:2m2s]\n",
      "[#9c1cff 3.9GiB/12GiB(30%) CN:16 DL:74MiB ETA:2m3s]\n",
      "[#9c1cff 4.0GiB/12GiB(31%) CN:16 DL:74MiB ETA:2m3s]\n",
      "[#9c1cff 4.0GiB/12GiB(31%) CN:16 DL:73MiB ETA:2m3s]\n",
      " *** Download Progress Summary as of Sun Jul  9 07:17:03 2023 *** \n",
      "===============================================================================\n",
      "[#9c1cff 4.1GiB/12GiB(32%) CN:16 DL:74MiB ETA:2m]\n",
      "FILE: /workspace/pretrained_model/sd_xl_base_0.9.safetensors\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "[#9c1cff 4.1GiB/12GiB(32%) CN:16 DL:74MiB ETA:2m]\n",
      "[#9c1cff 4.2GiB/12GiB(32%) CN:16 DL:74MiB ETA:1m59s]\n",
      "[#9c1cff 4.3GiB/12GiB(33%) CN:16 DL:75MiB ETA:1m57s]\n",
      "[#9c1cff 4.3GiB/12GiB(33%) CN:16 DL:74MiB ETA:1m57s]\n",
      "[#9c1cff 4.4GiB/12GiB(34%) CN:16 DL:74MiB ETA:1m56s]\n",
      "[#9c1cff 4.5GiB/12GiB(34%) CN:16 DL:74MiB ETA:1m55s]\n",
      "[#9c1cff 4.5GiB/12GiB(35%) CN:16 DL:74MiB ETA:1m54s]\n",
      "[#9c1cff 4.6GiB/12GiB(36%) CN:16 DL:74MiB ETA:1m53s]\n",
      "[#9c1cff 4.7GiB/12GiB(36%) CN:16 DL:74MiB ETA:1m53s]\n",
      "[#9c1cff 4.8GiB/12GiB(37%) CN:16 DL:74MiB ETA:1m51s]\n",
      "[#9c1cff 4.8GiB/12GiB(37%) CN:16 DL:74MiB ETA:1m51s]\n",
      " *** Download Progress Summary as of Sun Jul  9 07:17:14 2023 *** \n",
      "===============================================================================\n",
      "[#9c1cff 4.9GiB/12GiB(38%) CN:16 DL:73MiB ETA:1m51s]\n",
      "FILE: /workspace/pretrained_model/sd_xl_base_0.9.safetensors\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "[#9c1cff 4.9GiB/12GiB(38%) CN:16 DL:73MiB ETA:1m51s]\n",
      "[#9c1cff 5.0GiB/12GiB(38%) CN:16 DL:73MiB ETA:1m50s]\n",
      "[#9c1cff 5.0GiB/12GiB(39%) CN:16 DL:73MiB ETA:1m49s]\n",
      "[#9c1cff 5.1GiB/12GiB(39%) CN:16 DL:73MiB ETA:1m48s]\n",
      "[#9c1cff 5.2GiB/12GiB(40%) CN:16 DL:72MiB ETA:1m48s]\n",
      "[#9c1cff 5.3GiB/12GiB(41%) CN:16 DL:73MiB ETA:1m46s]\n",
      "[#9c1cff 5.3GiB/12GiB(41%) CN:16 DL:73MiB ETA:1m44s]\n",
      "[#9c1cff 5.4GiB/12GiB(42%) CN:16 DL:73MiB ETA:1m44s]\n",
      "[#9c1cff 5.5GiB/12GiB(42%) CN:16 DL:73MiB ETA:1m43s]\n",
      "[#9c1cff 5.5GiB/12GiB(43%) CN:16 DL:74MiB ETA:1m41s]\n",
      "[#9c1cff 5.6GiB/12GiB(43%) CN:16 DL:74MiB ETA:1m39s]\n",
      " *** Download Progress Summary as of Sun Jul  9 07:17:25 2023 *** \n",
      "===============================================================================\n",
      "[#9c1cff 5.7GiB/12GiB(44%) CN:16 DL:74MiB ETA:1m38s]\n",
      "FILE: /workspace/pretrained_model/sd_xl_base_0.9.safetensors\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "[#9c1cff 5.7GiB/12GiB(44%) CN:16 DL:74MiB ETA:1m38s]\n",
      "[#9c1cff 5.8GiB/12GiB(44%) CN:16 DL:75MiB ETA:1m36s]\n",
      "[#9c1cff 5.8GiB/12GiB(45%) CN:16 DL:75MiB ETA:1m35s]\n",
      "[#9c1cff 5.9GiB/12GiB(46%) CN:16 DL:75MiB ETA:1m33s]\n",
      "[#9c1cff 6.0GiB/12GiB(46%) CN:16 DL:75MiB ETA:1m32s]\n",
      "[#9c1cff 6.1GiB/12GiB(47%) CN:16 DL:75MiB ETA:1m32s]\n",
      "[#9c1cff 6.1GiB/12GiB(47%) CN:16 DL:75MiB ETA:1m31s]\n",
      "[#9c1cff 6.2GiB/12GiB(48%) CN:16 DL:75MiB ETA:1m30s]\n",
      "[#9c1cff 6.3GiB/12GiB(48%) CN:16 DL:75MiB ETA:1m29s]\n",
      "[#9c1cff 6.4GiB/12GiB(49%) CN:16 DL:75MiB ETA:1m28s]\n",
      " *** Download Progress Summary as of Sun Jul  9 07:17:35 2023 *** \n",
      "===============================================================================\n",
      "[#9c1cff 6.4GiB/12GiB(50%) CN:16 DL:75MiB ETA:1m27s]\n",
      "FILE: /workspace/pretrained_model/sd_xl_base_0.9.safetensors\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "[#9c1cff 6.4GiB/12GiB(50%) CN:16 DL:75MiB ETA:1m27s]\n",
      "[#9c1cff 6.5GiB/12GiB(50%) CN:16 DL:75MiB ETA:1m26s]\n",
      "[#9c1cff 6.6GiB/12GiB(51%) CN:16 DL:75MiB ETA:1m25s]\n",
      "[#9c1cff 6.6GiB/12GiB(51%) CN:16 DL:74MiB ETA:1m25s]\n",
      "[#9c1cff 6.7GiB/12GiB(52%) CN:16 DL:74MiB ETA:1m24s]\n",
      "[#9c1cff 6.8GiB/12GiB(52%) CN:16 DL:74MiB ETA:1m23s]\n",
      "[#9c1cff 6.9GiB/12GiB(53%) CN:16 DL:75MiB ETA:1m22s]\n",
      "[#9c1cff 6.9GiB/12GiB(54%) CN:16 DL:74MiB ETA:1m21s]\n",
      "[#9c1cff 7.0GiB/12GiB(54%) CN:16 DL:74MiB ETA:1m21s]\n",
      "[#9c1cff 7.1GiB/12GiB(55%) CN:16 DL:73MiB ETA:1m20s]\n",
      "[#9c1cff 7.1GiB/12GiB(55%) CN:16 DL:73MiB ETA:1m19s]\n",
      " *** Download Progress Summary as of Sun Jul  9 07:17:46 2023 *** \n",
      "===============================================================================\n",
      "[#9c1cff 7.2GiB/12GiB(56%) CN:16 DL:73MiB ETA:1m18s]\n",
      "FILE: /workspace/pretrained_model/sd_xl_base_0.9.safetensors\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "[#9c1cff 7.2GiB/12GiB(56%) CN:16 DL:73MiB ETA:1m18s]\n",
      "[#9c1cff 7.3GiB/12GiB(56%) CN:16 DL:73MiB ETA:1m17s]\n",
      "[#9c1cff 7.4GiB/12GiB(57%) CN:16 DL:73MiB ETA:1m16s]\n",
      "[#9c1cff 7.4GiB/12GiB(57%) CN:16 DL:73MiB ETA:1m15s]\n",
      "[#9c1cff 7.5GiB/12GiB(58%) CN:16 DL:74MiB ETA:1m13s]\n",
      "[#9c1cff 7.6GiB/12GiB(59%) CN:16 DL:74MiB ETA:1m12s]\n",
      "[#9c1cff 7.7GiB/12GiB(59%) CN:16 DL:74MiB ETA:1m11s]\n",
      "[#9c1cff 7.7GiB/12GiB(60%) CN:16 DL:74MiB ETA:1m10s]\n",
      "[#9c1cff 7.8GiB/12GiB(60%) CN:16 DL:74MiB ETA:1m10s]\n",
      "[#9c1cff 7.9GiB/12GiB(61%) CN:16 DL:73MiB ETA:1m9s]\n",
      "[#9c1cff 7.9GiB/12GiB(61%) CN:16 DL:74MiB ETA:1m8s]\n",
      " *** Download Progress Summary as of Sun Jul  9 07:17:57 2023 *** \n",
      "===============================================================================\n",
      "[#9c1cff 8.0GiB/12GiB(62%) CN:16 DL:74MiB ETA:1m6s]\n",
      "FILE: /workspace/pretrained_model/sd_xl_base_0.9.safetensors\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "[#9c1cff 8.0GiB/12GiB(62%) CN:16 DL:74MiB ETA:1m6s]\n",
      "[#9c1cff 8.1GiB/12GiB(62%) CN:16 DL:74MiB ETA:1m5s]\n",
      "[#9c1cff 8.2GiB/12GiB(63%) CN:16 DL:74MiB ETA:1m4s]\n",
      "[#9c1cff 8.2GiB/12GiB(63%) CN:16 DL:73MiB ETA:1m5s]\n",
      "[#9c1cff 8.3GiB/12GiB(64%) CN:16 DL:72MiB ETA:1m4s]\n",
      "[#9c1cff 8.4GiB/12GiB(65%) CN:16 DL:72MiB ETA:1m3s]\n",
      "[#9c1cff 8.4GiB/12GiB(65%) CN:16 DL:71MiB ETA:1m3s]\n",
      "[#9c1cff 8.5GiB/12GiB(66%) CN:16 DL:71MiB ETA:1m2s]\n",
      "[#9c1cff 8.6GiB/12GiB(66%) CN:16 DL:71MiB ETA:1m1s]\n",
      "[#9c1cff 8.6GiB/12GiB(67%) CN:16 DL:70MiB ETA:1m1s]\n",
      "[#9c1cff 8.7GiB/12GiB(67%) CN:16 DL:70MiB ETA:1m]\n",
      " *** Download Progress Summary as of Sun Jul  9 07:18:08 2023 *** \n",
      "===============================================================================\n",
      "[#9c1cff 8.8GiB/12GiB(68%) CN:16 DL:70MiB ETA:59s]\n",
      "FILE: /workspace/pretrained_model/sd_xl_base_0.9.safetensors\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "[#9c1cff 8.8GiB/12GiB(68%) CN:16 DL:70MiB ETA:59s]\n",
      "[#9c1cff 8.8GiB/12GiB(68%) CN:16 DL:71MiB ETA:57s]\n",
      "[#9c1cff 8.9GiB/12GiB(69%) CN:16 DL:71MiB ETA:56s]\n",
      "[#9c1cff 9.0GiB/12GiB(69%) CN:16 DL:72MiB ETA:55s]\n",
      "[#9c1cff 9.1GiB/12GiB(70%) CN:16 DL:73MiB ETA:53s]\n",
      "[#9c1cff 9.1GiB/12GiB(71%) CN:16 DL:74MiB ETA:51s]\n",
      "[#9c1cff 9.2GiB/12GiB(71%) CN:16 DL:75MiB ETA:49s]\n",
      "[#9c1cff 9.3GiB/12GiB(72%) CN:16 DL:75MiB ETA:48s]\n",
      "[#9c1cff 9.4GiB/12GiB(72%) CN:16 DL:76MiB ETA:47s]\n",
      "[#9c1cff 9.4GiB/12GiB(73%) CN:16 DL:76MiB ETA:46s]\n",
      "[#9c1cff 9.5GiB/12GiB(74%) CN:16 DL:76MiB ETA:44s]\n",
      " *** Download Progress Summary as of Sun Jul  9 07:18:19 2023 *** \n",
      "===============================================================================\n",
      "[#9c1cff 9.6GiB/12GiB(74%) CN:16 DL:76MiB ETA:43s]\n",
      "FILE: /workspace/pretrained_model/sd_xl_base_0.9.safetensors\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "[#9c1cff 9.6GiB/12GiB(74%) CN:16 DL:76MiB ETA:43s]\n",
      "[#9c1cff 9.7GiB/12GiB(75%) CN:16 DL:76MiB ETA:42s]\n",
      "[#9c1cff 9.7GiB/12GiB(75%) CN:16 DL:77MiB ETA:41s]\n",
      "[#9c1cff 9.8GiB/12GiB(76%) CN:16 DL:77MiB ETA:40s]\n",
      "[#9c1cff 9.9GiB/12GiB(77%) CN:15 DL:77MiB ETA:39s]\n",
      "[#9c1cff 10GiB/12GiB(77%) CN:16 DL:77MiB ETA:38s]\n",
      "[#9c1cff 10GiB/12GiB(78%) CN:16 DL:77MiB ETA:37s]\n",
      "[#9c1cff 10GiB/12GiB(78%) CN:16 DL:77MiB ETA:36s]\n",
      "[#9c1cff 10GiB/12GiB(79%) CN:16 DL:77MiB ETA:35s]\n",
      "[#9c1cff 10GiB/12GiB(79%) CN:16 DL:76MiB ETA:35s]\n",
      "[#9c1cff 10GiB/12GiB(80%) CN:16 DL:77MiB ETA:33s]\n",
      " *** Download Progress Summary as of Sun Jul  9 07:18:30 2023 *** \n",
      "===============================================================================\n",
      "[#9c1cff 10GiB/12GiB(81%) CN:16 DL:77MiB ETA:32s]\n",
      "FILE: /workspace/pretrained_model/sd_xl_base_0.9.safetensors\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "[#9c1cff 10GiB/12GiB(81%) CN:16 DL:77MiB ETA:32s]\n",
      "[#9c1cff 10GiB/12GiB(81%) CN:16 DL:76MiB ETA:31s]\n",
      "[#9c1cff 10GiB/12GiB(82%) CN:16 DL:75MiB ETA:31s]\n",
      "[#9c1cff 10GiB/12GiB(82%) CN:16 DL:75MiB ETA:30s]\n",
      "[#9c1cff 10GiB/12GiB(83%) CN:16 DL:75MiB ETA:29s]\n",
      "[#9c1cff 10GiB/12GiB(83%) CN:16 DL:75MiB ETA:28s]\n",
      "[#9c1cff 10GiB/12GiB(84%) CN:16 DL:76MiB ETA:27s]\n",
      "[#9c1cff 10GiB/12GiB(84%) CN:16 DL:76MiB ETA:26s]\n",
      "[#9c1cff 11GiB/12GiB(85%) CN:16 DL:76MiB ETA:25s]\n",
      "[#9c1cff 11GiB/12GiB(86%) CN:16 DL:75MiB ETA:24s]\n",
      "[#9c1cff 11GiB/12GiB(86%) CN:16 DL:75MiB ETA:23s]\n",
      " *** Download Progress Summary as of Sun Jul  9 07:18:41 2023 *** \n",
      "===============================================================================\n",
      "[#9c1cff 11GiB/12GiB(87%) CN:16 DL:76MiB ETA:22s]\n",
      "FILE: /workspace/pretrained_model/sd_xl_base_0.9.safetensors\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "[#9c1cff 11GiB/12GiB(87%) CN:16 DL:76MiB ETA:22s]\n",
      "[#9c1cff 11GiB/12GiB(87%) CN:16 DL:76MiB ETA:21s]\n",
      "[#9c1cff 11GiB/12GiB(88%) CN:16 DL:76MiB ETA:19s]\n",
      "[#9c1cff 11GiB/12GiB(89%) CN:16 DL:77MiB ETA:18s]\n",
      "[#9c1cff 11GiB/12GiB(89%) CN:16 DL:76MiB ETA:18s]\n",
      "[#9c1cff 11GiB/12GiB(90%) CN:16 DL:76MiB ETA:17s]\n",
      "[#9c1cff 11GiB/12GiB(90%) CN:16 DL:76MiB ETA:16s]\n",
      "[#9c1cff 11GiB/12GiB(91%) CN:16 DL:76MiB ETA:15s]\n",
      "[#9c1cff 11GiB/12GiB(91%) CN:16 DL:76MiB ETA:14s]\n",
      "[#9c1cff 11GiB/12GiB(92%) CN:16 DL:76MiB ETA:13s]\n",
      "[#9c1cff 12GiB/12GiB(93%) CN:16 DL:76MiB ETA:12s]\n",
      " *** Download Progress Summary as of Sun Jul  9 07:18:52 2023 *** \n",
      "===============================================================================\n",
      "[#9c1cff 12GiB/12GiB(93%) CN:16 DL:76MiB ETA:11s]\n",
      "FILE: /workspace/pretrained_model/sd_xl_base_0.9.safetensors\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "[#9c1cff 12GiB/12GiB(93%) CN:16 DL:76MiB ETA:11s]\n",
      "[#9c1cff 12GiB/12GiB(94%) CN:16 DL:76MiB ETA:9s]\n",
      "[#9c1cff 12GiB/12GiB(94%) CN:16 DL:77MiB ETA:8s]\n",
      "[#9c1cff 12GiB/12GiB(95%) CN:16 DL:77MiB ETA:7s]\n",
      "[#9c1cff 12GiB/12GiB(95%) CN:16 DL:77MiB ETA:6s]\n",
      "[#9c1cff 12GiB/12GiB(96%) CN:16 DL:76MiB ETA:5s]\n",
      "[#9c1cff 12GiB/12GiB(97%) CN:16 DL:76MiB ETA:5s]\n",
      "[#9c1cff 12GiB/12GiB(97%) CN:16 DL:76MiB ETA:4s]\n",
      "[#9c1cff 12GiB/12GiB(98%) CN:16 DL:76MiB ETA:3s]\n",
      "[#9c1cff 12GiB/12GiB(98%) CN:16 DL:76MiB ETA:2s]\n",
      "[#9c1cff 12GiB/12GiB(99%) CN:16 DL:76MiB]\n",
      " *** Download Progress Summary as of Sun Jul  9 07:19:03 2023 *** \n",
      "===============================================================================\n",
      "[#9c1cff 12GiB/12GiB(99%) CN:4 DL:76MiB]\n",
      "FILE: /workspace/pretrained_model/sd_xl_base_0.9.safetensors\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "[#9c1cff 12GiB/12GiB(99%) CN:4 DL:76MiB]\n",
      "\n",
      "Download Results:\n",
      "gid   |stat|avg speed  |path/URI\n",
      "======+====+===========+=======================================================\n",
      "9c1cff|OK  |    75MiB/s|/workspace/pretrained_model/sd_xl_base_0.9.safetensors\n",
      "\n",
      "Status Legend:\n",
      "(OK):download completed.\n",
      "[#dd6a15 0B/319MiB(0%) CN:1 DL:0B] [FileAlloc:#dd6a15 226MiB/319MiB(71%)]\n",
      "[#dd6a15 43MiB/319MiB(13%) CN:16 DL:61MiB ETA:4s]\n",
      "[#dd6a15 115MiB/319MiB(36%) CN:16 DL:67MiB ETA:3s]\n",
      "[#dd6a15 178MiB/319MiB(56%) CN:16 DL:66MiB ETA:2s]\n",
      "[#dd6a15 241MiB/319MiB(75%) CN:16 DL:65MiB ETA:1s]\n",
      "[#dd6a15 311MiB/319MiB(97%) CN:14 DL:66MiB]\n",
      "\n",
      "Download Results:\n",
      "gid   |stat|avg speed  |path/URI\n",
      "======+====+===========+=======================================================\n",
      "dd6a15|OK  |    64MiB/s|/workspace/vae/sdxl_vae.safetensors\n",
      "\n",
      "Status Legend:\n",
      "(OK):download completed.\n",
      "Selected model: /workspace/pretrained_model/sd_xl_base_0.9.safetensors\n",
      "Selected vae: /workspace/vae/sdxl_vae.safetensors\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import requests\n",
    "import subprocess\n",
    "from urllib.parse import urlparse, unquote\n",
    "from pathlib import Path\n",
    "\n",
    "os.chdir(root_dir)\n",
    "\n",
    "HUGGINGFACE_TOKEN = \"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\"\n",
    "SDXL_MODEL_URL    = \"https://huggingface.co/stabilityai/stable-diffusion-xl-base-0.9/resolve/main/sd_xl_base_0.9.safetensors\"\n",
    "SDXL_VAE_URL      = \"https://huggingface.co/stabilityai/sdxl-vae/resolve/main/sdxl_vae.safetensors\"\n",
    "\n",
    "def get_supported_extensions():\n",
    "    return tuple([\".ckpt\", \".safetensors\", \".pt\", \".pth\"])\n",
    "\n",
    "def get_filename(url, bearer_token, quiet=True):\n",
    "    headers = {\"Authorization\": f\"Bearer {bearer_token}\"}\n",
    "    response = requests.get(url, headers=headers, stream=True)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    if 'content-disposition' in response.headers:\n",
    "        content_disposition = response.headers['content-disposition']\n",
    "        filename = re.findall('filename=\"?([^\"]+)\"?', content_disposition)[0]\n",
    "    else:\n",
    "        url_path = urlparse(url).path\n",
    "        filename = unquote(os.path.basename(url_path))\n",
    "\n",
    "    return filename\n",
    "\n",
    "def parse_args(config):\n",
    "    args = []\n",
    "\n",
    "    for k, v in config.items():\n",
    "        if k.startswith(\"_\"):\n",
    "            args.append(f\"{v}\")\n",
    "        elif isinstance(v, str) and v is not None:\n",
    "            args.append(f'--{k}={v}')\n",
    "        elif isinstance(v, bool) and v:\n",
    "            args.append(f\"--{k}\")\n",
    "        elif isinstance(v, float) and not isinstance(v, bool):\n",
    "            args.append(f\"--{k}={v}\")\n",
    "        elif isinstance(v, int) and not isinstance(v, bool):\n",
    "            args.append(f\"--{k}={v}\")\n",
    "\n",
    "    return args\n",
    "\n",
    "def aria2_download(dir, filename, url, token):\n",
    "    user_header = f\"Authorization: Bearer {token}\"\n",
    "\n",
    "    aria2_config = {\n",
    "        \"console-log-level\"         : \"error\",\n",
    "        \"summary-interval\"          : 10,\n",
    "        \"header\"                    : user_header if \"huggingface.co\" in url else None,\n",
    "        \"continue\"                  : True,\n",
    "        \"max-connection-per-server\" : 16,\n",
    "        \"min-split-size\"            : \"1M\",\n",
    "        \"split\"                     : 16,\n",
    "        \"dir\"                       : dir,\n",
    "        \"out\"                       : filename,\n",
    "        \"_url\"                      : url,\n",
    "    }\n",
    "    aria2_args = parse_args(aria2_config)\n",
    "    subprocess.run([\"aria2c\", *aria2_args])\n",
    "\n",
    "def download(url, dst, token):\n",
    "    filename = get_filename(url, token, quiet=False)\n",
    "    filepath = os.path.join(dst, filename)\n",
    "\n",
    "    if url.startswith(\"/workspace\"):\n",
    "        return url\n",
    "    elif \"huggingface.co\" in url:\n",
    "        if \"/blob/\" in url:\n",
    "            url = url.replace(\"/blob/\", \"/resolve/\")\n",
    "                \n",
    "        aria2_download(dst, filename, url, token)\n",
    "\n",
    "    return filepath\n",
    "\n",
    "def main():\n",
    "    global model_path, vae_path\n",
    "\n",
    "    model_path = vae_path = None\n",
    "\n",
    "    download_targets = {\n",
    "        \"model\" : (SDXL_MODEL_URL, pretrained_model),\n",
    "        \"vae\"   : (SDXL_VAE_URL, vae_dir),\n",
    "    }\n",
    "    selected_files = {}\n",
    "\n",
    "    for target, (url, dst) in download_targets.items():\n",
    "        if url:\n",
    "            downloader = download(url, dst, HUGGINGFACE_TOKEN)\n",
    "            selected_files[target] = downloader\n",
    "\n",
    "            if target == \"model\":\n",
    "                model_path = selected_files[\"model\"] if not downloader else downloader\n",
    "            elif target == \"vae\":\n",
    "                vae_path = selected_files[\"vae\"] if not downloader else downloader\n",
    "\n",
    "    for category, path in {\n",
    "        \"model\": model_path,\n",
    "        \"vae\": vae_path,\n",
    "    }.items():\n",
    "        if path is not None and os.path.exists(path):\n",
    "            print(f\"Selected {category}: {path}\")\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525cdc14-d546-4cf4-a854-0877b65bb75f",
   "metadata": {},
   "source": [
    "# Directory Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63254a56-77e9-45d5-ac58-745a70c2459e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your train data directory : /workspace/fine_tune/train_data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "train_data_dir = \"/workspace/fine_tune/train_data\"\n",
    "\n",
    "os.makedirs(train_data_dir, exist_ok=True)\n",
    "print(f\"Your train data directory : {train_data_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5062b8e7-a53c-4072-983e-45d41d8cf771",
   "metadata": {},
   "source": [
    "# Data Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eeba204-3abe-4e5e-af6f-3cac048e2407",
   "metadata": {},
   "source": [
    "## Unzip Dataset\n",
    "If your dataset is in a `zip` file and has been uploaded to a location, use this section to extract it. The dataset will be downloaded and automatically extracted to `train_data_dir` if `unzip_to` is empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "240535e0-b9c0-4e17-b278-c8df0dc56ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[#baaba7 0B/1.0GiB(0%) CN:1 DL:0B] [FileAlloc:#baaba7 377MiB/1.0GiB(33%)]\n",
      "[#baaba7 0B/1.0GiB(0%) CN:1 DL:0B] [FileAlloc:#baaba7 0.9GiB/1.0GiB(83%)]\n",
      "[#baaba7 34MiB/1.0GiB(3%) CN:16 DL:62MiB ETA:17s]\n",
      "[#baaba7 118MiB/1.0GiB(10%) CN:16 DL:76MiB ETA:13s]\n",
      "[#baaba7 196MiB/1.0GiB(17%) CN:16 DL:76MiB ETA:11s]\n",
      "[#baaba7 275MiB/1.0GiB(24%) CN:16 DL:77MiB ETA:10s]\n",
      "[#baaba7 354MiB/1.0GiB(31%) CN:16 DL:77MiB ETA:9s]\n",
      "[#baaba7 434MiB/1.0GiB(39%) CN:16 DL:78MiB ETA:8s]\n",
      "[#baaba7 514MiB/1.0GiB(46%) CN:16 DL:78MiB ETA:7s]\n",
      "[#baaba7 595MiB/1.0GiB(53%) CN:16 DL:78MiB ETA:6s]\n",
      " *** Download Progress Summary as of Sun Jul  9 07:35:03 2023 *** \n",
      "===============================================================================\n",
      "[#baaba7 677MiB/1.0GiB(60%) CN:16 DL:79MiB ETA:5s]\n",
      "FILE: /workspace/hitokomoru_dataset.zip\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "[#baaba7 677MiB/1.0GiB(60%) CN:16 DL:79MiB ETA:5s]\n",
      "[#baaba7 756MiB/1.0GiB(67%) CN:16 DL:79MiB ETA:4s]\n",
      "[#baaba7 835MiB/1.0GiB(75%) CN:16 DL:80MiB ETA:3s]\n",
      "[#baaba7 911MiB/1.0GiB(81%) CN:16 DL:79MiB ETA:2s]\n",
      "[#baaba7 0.9GiB/1.0GiB(89%) CN:16 DL:79MiB ETA:1s]\n",
      "[#baaba7 1.0GiB/1.0GiB(97%) CN:15 DL:80MiB]\n",
      "\n",
      "Download Results:\n",
      "gid   |stat|avg speed  |path/URI\n",
      "======+====+===========+=======================================================\n",
      "baaba7|OK  |    78MiB/s|/workspace/hitokomoru_dataset.zip\n",
      "\n",
      "Status Legend:\n",
      "(OK):download completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "zipfile_url  = \"https://huggingface.co/datasets/Linaqruf/hitokomoru-lora-dataset/resolve/main/hitokomoru_dataset.zip\"\n",
    "unzip_to     = \"\"\n",
    "\n",
    "if unzip_to:\n",
    "    os.makedirs(unzip_to, exist_ok=True)\n",
    "else:\n",
    "    unzip_to = train_data_dir\n",
    "\n",
    "def extract_dataset(zip_file, output_path):\n",
    "    with zipfile.ZipFile(zip_file, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(output_path)\n",
    "        \n",
    "def remove_files(train_dir, files_to_move):\n",
    "    for filename in os.listdir(train_dir):\n",
    "        file_path = os.path.join(train_dir, filename)\n",
    "        if filename in files_to_move:\n",
    "            if not os.path.exists(file_path):\n",
    "                shutil.move(file_path, training_dir)\n",
    "            else:\n",
    "                os.remove(file_path)\n",
    "\n",
    "zip_file = download(zipfile_url, root_dir, HUGGINGFACE_TOKEN)\n",
    "extract_dataset(zip_file, unzip_to)\n",
    "os.remove(zip_file)\n",
    "\n",
    "files_to_move = (\n",
    "    \"meta_cap.json\",\n",
    "    \"meta_cap_dd.json\",\n",
    "    \"meta_lat.json\",\n",
    "    \"meta_clean.json\",\n",
    ")\n",
    "\n",
    "remove_files(train_data_dir, files_to_move)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e29913-5b62-455b-bd53-d293ee7c9840",
   "metadata": {},
   "source": [
    "# Bucketing and Latents Caching\n",
    "This code will create buckets based on the `bucket_resolution` provided for multi-aspect ratio training, and then convert all images within the `train_data_dir` to latents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e521a3f-7b1b-4214-8806-2df6a12f98a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 98 images.\n",
      "Creating a new metadata file\n",
      "Merging tags and captions into metadata json.\n",
      "100%|██████████████████████████████████████████| 98/98 [00:00<00:00, 154.24it/s]\n",
      "All 98 images have captions\n",
      "All 98 images have tags\n",
      "Cleaning captions and tags.\n",
      "100%|█████████████████████████████████████████| 98/98 [00:00<00:00, 2276.16it/s]\n",
      "Writing metadata: /workspace/fine_tune/meta_clean.json\n",
      "Done!\n",
      "found 98 images.\n",
      "loading existing metadata: /workspace/fine_tune/meta_clean.json\n",
      "load VAE: /workspace/pretrained_model/sd_xl_base_0.9.safetensors\n",
      "100%|███████████████████████████████████████████| 98/98 [00:34<00:00,  2.87it/s]\n",
      "bucket 0 (576, 1024): 1\n",
      "bucket 1 (640, 1024): 2\n",
      "bucket 2 (704, 1024): 10\n",
      "bucket 3 (768, 1024): 24\n",
      "bucket 4 (832, 1024): 14\n",
      "bucket 5 (896, 1024): 14\n",
      "bucket 6 (960, 1024): 8\n",
      "bucket 7 (1024, 576): 1\n",
      "bucket 8 (1024, 640): 8\n",
      "bucket 9 (1024, 704): 6\n",
      "bucket 10 (1024, 768): 4\n",
      "bucket 11 (1024, 832): 1\n",
      "bucket 12 (1024, 896): 3\n",
      "bucket 13 (1024, 1024): 2\n",
      "mean ar error: 0.01832989347279542\n",
      "writing metadata: /workspace/fine_tune/meta_lat.json\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "# @title ## **3.4. Bucketing and Latents Caching**\n",
    "\n",
    "bucketing_json    = os.path.join(training_dir, \"meta_lat.json\")\n",
    "metadata_json     = os.path.join(training_dir, \"meta_clean.json\")\n",
    "bucket_resolution = 1024\n",
    "mixed_precision   = \"no\" # choose between [\"no\", \"fp16\", \"bf16\"]\n",
    "flip_aug          = False \n",
    "\n",
    "# Use `clean_caption` option to clean such as duplicate tags, `women` to `girl`, etc\n",
    "clean_caption     = True \n",
    "# Use the `recursive` option to process subfolders as well\n",
    "recursive         = True\n",
    "\n",
    "metadata_config = {\n",
    "    \"_train_data_dir\": train_data_dir,\n",
    "    \"_out_json\": metadata_json,\n",
    "    \"recursive\": recursive,\n",
    "    \"full_path\": recursive,\n",
    "    \"clean_caption\": clean_caption\n",
    "}\n",
    "\n",
    "bucketing_config = {\n",
    "    \"_train_data_dir\": train_data_dir,\n",
    "    \"_in_json\": metadata_json,\n",
    "    \"_out_json\": bucketing_json,\n",
    "    \"_model_name_or_path\": model_path,\n",
    "    \"recursive\": recursive,\n",
    "    \"full_path\": recursive,\n",
    "    \"flip_aug\": flip_aug,\n",
    "    \"batch_size\": 4,\n",
    "    \"max_data_loader_n_workers\": 2,\n",
    "    \"max_resolution\": f\"{bucket_resolution}, {bucket_resolution}\",\n",
    "    \"mixed_precision\": mixed_precision,\n",
    "}\n",
    "\n",
    "def generate_args(config):\n",
    "    args = \"\"\n",
    "    for k, v in config.items():\n",
    "        if k.startswith(\"_\"):\n",
    "            args += f'\"{v}\" '\n",
    "        elif isinstance(v, str):\n",
    "            args += f'--{k}=\"{v}\" '\n",
    "        elif isinstance(v, bool) and v:\n",
    "            args += f\"--{k} \"\n",
    "        elif isinstance(v, float) and not isinstance(v, bool):\n",
    "            args += f\"--{k}={v} \"\n",
    "        elif isinstance(v, int) and not isinstance(v, bool):\n",
    "            args += f\"--{k}={v} \"\n",
    "    return args.strip()\n",
    "\n",
    "merge_metadata_args = generate_args(metadata_config)\n",
    "prepare_buckets_args = generate_args(bucketing_config)\n",
    "\n",
    "merge_metadata_command = f\"python merge_all_to_metadata.py {merge_metadata_args}\"\n",
    "prepare_buckets_command = f\"python prepare_buckets_latents.py {prepare_buckets_args}\"\n",
    "\n",
    "os.chdir(finetune_dir)\n",
    "!{merge_metadata_command}\n",
    "time.sleep(1)\n",
    "!{prepare_buckets_command}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11483fb8-d0d1-4669-aa5f-b324708f614a",
   "metadata": {},
   "source": [
    "# Optimizer Config\n",
    "\n",
    "1. For `optimizer_type`, use `Adafactor` optimizer. `RMSprop 8bit` or `Adagrad 8bit` may work. `AdamW 8bit` doesn't seem to work.\n",
    "2. Choose between [\"AdamW\", \"AdamW8bit\", \"Lion8bit\", \"Lion\", \"SGDNesterov\", \"SGDNesterov8bit\", \"DAdaptation(DAdaptAdamPreprint)\", \"DAdaptAdaGrad\", \"DAdaptAdam\", \"DAdaptAdan\", \"DAdaptAdanIP\", \"DAdaptLion\", \"DAdaptSGD\", \"AdaFactor\"]\n",
    "3. Specify `optimizer_args` to add `additional` args for optimizer, e.g: `[\"weight_decay=0.6\"]`\n",
    "4. It's not recommended to Train Text Encoder for SDXL\n",
    "5. `lr_scheduler` provides several methods to adjust the learning rate based on the number of epochs.\n",
    "6. Choose between [\"linear\", \"cosine\", \"cosine_with_restarts\", \"polynomial\", \"constant\", \"constant_with_warmup\", \"adafactor\"]\n",
    "7. Specify `lr_scheduler_num` with `num_cycles` value for `cosine_with_restarts` or `power` value for `polynomial`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba8f1071-b7a1-4c9a-8550-99f8fc4bc01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[optimizer_arguments]\n",
      "optimizer_type = \"AdaFactor\"\n",
      "learning_rate = 4e-7\n",
      "train_text_encoder = false\n",
      "max_grad_norm = 1.0\n",
      "optimizer_args = [ \"scale_parameter=False\", \"relative_step=False\", \"warmup_init=False\",]\n",
      "lr_scheduler = \"constant_with_warmup\"\n",
      "lr_warmup_steps = 100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import toml\n",
    "import ast\n",
    "\n",
    "optimizer_type = \"AdaFactor\"  \n",
    "optimizer_args = \"[ \\\"scale_parameter=False\\\", \\\"relative_step=False\\\", \\\"warmup_init=False\\\" ]\"\n",
    "learning_rate = 4e-7\n",
    "train_text_encoder = False\n",
    "lr_scheduler = \"constant_with_warmup\" \n",
    "lr_warmup_steps = 100\n",
    "lr_scheduler_num = 0\n",
    "\n",
    "if isinstance(optimizer_args, str):\n",
    "    optimizer_args = optimizer_args.strip()\n",
    "    if optimizer_args.startswith('[') and optimizer_args.endswith(']'):\n",
    "        try:\n",
    "            optimizer_args = ast.literal_eval(optimizer_args)\n",
    "        except (SyntaxError, ValueError) as e:\n",
    "            print(f\"Error parsing optimizer_args: {e}\\n\")\n",
    "            optimizer_args = []\n",
    "    elif len(optimizer_args) > 0:\n",
    "        print(f\"WARNING! '{optimizer_args}' is not a valid list! Put args like this: [\\\"args=1\\\", \\\"args=2\\\"]\\n\")\n",
    "        optimizer_args = []\n",
    "    else:\n",
    "        optimizer_args = []\n",
    "else:\n",
    "    optimizer_args = []\n",
    "\n",
    "optimizer_config = {\n",
    "    \"optimizer_arguments\": {\n",
    "        \"optimizer_type\"          : optimizer_type,\n",
    "        \"learning_rate\"           : learning_rate,\n",
    "        \"train_text_encoder\"      : train_text_encoder,\n",
    "        \"max_grad_norm\"           : 1.0,\n",
    "        \"optimizer_args\"          : optimizer_args,\n",
    "        \"lr_scheduler\"            : lr_scheduler,\n",
    "        \"lr_warmup_steps\"         : lr_warmup_steps,\n",
    "        \"lr_scheduler_num_cycles\" : lr_scheduler_num if lr_scheduler == \"cosine_with_restarts\" else None,\n",
    "        \"lr_scheduler_power\"      : lr_scheduler_num if lr_scheduler == \"polynomial\" else None,\n",
    "        \"lr_scheduler_type\"       : None,\n",
    "        \"lr_scheduler_args\"       : None,\n",
    "    },\n",
    "}\n",
    "\n",
    "print(toml.dumps(optimizer_config))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620ce942-f3f8-4d4f-b2b4-7c807cf35851",
   "metadata": {},
   "source": [
    "# Advanced Training Config\n",
    "1. Specify `optimizer_state_path` to resume training with Optimizer State\n",
    "2. You can't use both `noise_offset` and `multires_noise` at the same time\n",
    "3. Uncomment if necessary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "13fced50-aaeb-4101-936f-0689b0bf8e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[advanced_training_config]\n",
      "resume = \"\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import toml\n",
    "\n",
    "optimizer_state_path      = \"\" \n",
    "# noise_offset          = 0.1 \n",
    "# multires_noise_iterations = 6 \n",
    "# multires_noise_discount = 0.3\n",
    "min_snr_gamma             = -1 \n",
    "\n",
    "advanced_training_config = {\n",
    "    \"advanced_training_config\": {\n",
    "        \"resume\"                    : optimizer_state_path,\n",
    "        # \"noise_offset\"              : noise_offset, \n",
    "        # \"multires_noise_iterations\" : multires_noise_iterations, \n",
    "        # \"multires_noise_discount\"   : multires_noise_discount, \n",
    "        \"min_snr_gamma\"             : min_snr_gamma if not min_snr_gamma == -1 else None,\n",
    "\n",
    "    }\n",
    "}\n",
    "\n",
    "print(toml.dumps(advanced_training_config))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5dce50-df19-4e60-b326-ea9841599e14",
   "metadata": {},
   "source": [
    "# Deployment Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "31a22e72-2fcf-4131-a012-1297aee350f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_to_hub_config]\n",
      "huggingface_repo_id = \"sdxl_finetune\"\n",
      "huggingface_repo_type = \"model\"\n",
      "huggingface_path_in_repo = \"\"\n",
      "huggingface_token = \"\"\n",
      "async_upload = true\n",
      "huggingface_repo_visibility = \"private\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import toml\n",
    "\n",
    "huggingface_repo_id = \"sdxl_finetune\"\n",
    "huggingface_write_token = \"\"\n",
    "huggingface_path_in_repo = \"\"\n",
    "huggingface_repo_visibility = \"private\" # private or public\n",
    "async_upload = True\n",
    "\n",
    "deployment_config = {\n",
    "    \"save_to_hub_config\": {\n",
    "        \"huggingface_repo_id\"         : huggingface_repo_id,\n",
    "        \"huggingface_repo_type\"       : \"model\", \n",
    "        \"huggingface_path_in_repo\"    : huggingface_path_in_repo, \n",
    "        \"huggingface_token\"           : huggingface_write_token,\n",
    "        \"async_upload\"                : async_upload, \n",
    "        \"huggingface_repo_visibility\" : huggingface_repo_visibility,\n",
    "    }\n",
    "}\n",
    "print(toml.dumps(deployment_config))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87792429-20e3-464a-9ce4-95abcc6af155",
   "metadata": {},
   "source": [
    "# Training Config \n",
    "1. Get your `wandb_api_key` here: https://wandb.ai/settings\n",
    "2. `cache_text_encoder_outputs` is the recommended parameter for SDXL training but if you enable it, `shuffle_caption` won't work\n",
    "3. `min_timestep` and `max_timestep` can be used to train U-Net with different timesteps. The default values are 0 and 1000.\n",
    "4. Sampler List: [\"ddim\", \"pndm\", \"lms\", \"euler\", \"euler_a\", \"heun\", \"dpm_2\", \"dpm_2_a\", \"dpmsolver\",\"dpmsolver++\", \"dpmsingle\", \"k_lms\", \"k_euler\", \"k_euler_a\", \"k_dpm_2\", \"k_dpm_2_a\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "79fa0e7f-9254-475f-95eb-96bc5c5cefd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sdxl_arguments]\n",
      "cache_text_encoder_outputs = true\n",
      "no_half_vae = true\n",
      "min_timestep = 0\n",
      "max_timestep = 1000\n",
      "shuffle_caption = false\n",
      "\n",
      "[model_arguments]\n",
      "pretrained_model_name_or_path = \"/workspace/pretrained_model/sd_xl_base_0.9.safetensors\"\n",
      "vae = \"/workspace/vae/sdxl_vae.safetensors\"\n",
      "\n",
      "[dataset_arguments]\n",
      "debug_dataset = false\n",
      "in_json = \"/workspace/fine_tune/meta_lat.json\"\n",
      "train_data_dir = \"/workspace/fine_tune/train_data\"\n",
      "dataset_repeats = 1\n",
      "keep_tokens = 0\n",
      "resolution = \"1024,1024\"\n",
      "caption_dropout_rate = 0\n",
      "caption_tag_dropout_rate = 0\n",
      "caption_dropout_every_n_epochs = 0\n",
      "color_aug = false\n",
      "token_warmup_min = 1\n",
      "token_warmup_step = 0\n",
      "\n",
      "[training_arguments]\n",
      "output_dir = \"/workspace/fine_tune/outputs\"\n",
      "output_name = \"sdxl_finetune\"\n",
      "save_precision = \"fp16\"\n",
      "save_every_n_steps = 1000\n",
      "train_batch_size = 1\n",
      "max_token_length = 225\n",
      "mem_eff_attn = false\n",
      "xformers = true\n",
      "max_train_steps = 2500\n",
      "max_data_loader_n_workers = 8\n",
      "persistent_data_loader_workers = true\n",
      "gradient_checkpointing = true\n",
      "gradient_accumulation_steps = 1\n",
      "mixed_precision = \"fp16\"\n",
      "\n",
      "[logging_arguments]\n",
      "log_with = \"tensorboard\"\n",
      "logging_dir = \"/workspace/fine_tune/logs\"\n",
      "log_prefix = \"sdxl_finetune\"\n",
      "\n",
      "[sample_prompt_arguments]\n",
      "sample_every_n_steps = 100\n",
      "sample_sampler = \"euler_a\"\n",
      "\n",
      "[saving_arguments]\n",
      "save_model_as = \"safetensors\"\n",
      "\n",
      "[optimizer_arguments]\n",
      "optimizer_type = \"AdaFactor\"\n",
      "learning_rate = 4e-7\n",
      "train_text_encoder = false\n",
      "max_grad_norm = 1.0\n",
      "optimizer_args = [ \"scale_parameter=False\", \"relative_step=False\", \"warmup_init=False\",]\n",
      "lr_scheduler = \"constant_with_warmup\"\n",
      "lr_warmup_steps = 100\n",
      "\n",
      "[advanced_training_config]\n",
      "\n",
      "[save_to_hub_config]\n",
      "huggingface_repo_id = \"sdxl_finetune\"\n",
      "huggingface_repo_type = \"model\"\n",
      "async_upload = true\n",
      "huggingface_repo_visibility = \"private\"\n",
      "\n",
      "[prompt]\n",
      "negative_prompt = \"3d render, smooth, plastic, blurry, grainy, low-resolution, deep-fried, oversaturated\"\n",
      "width = 1024\n",
      "height = 1024\n",
      "scale = 7\n",
      "sample_steps = 28\n",
      "[[prompt.subset]]\n",
      "prompt = \"1girl, aqua eyes, baseball cap, blonde hair, closed mouth, earrings, green background, hat, hoop earrings, jewelry, looking at viewer, shirt, short hair, simple background, solo, upper body, yellow shirt\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import toml\n",
    "import os\n",
    "import random\n",
    "from subprocess import getoutput\n",
    "\n",
    "# PROJECT CONFIG\n",
    "project_name            = \"sdxl_finetune\"\n",
    "wandb_api_key           = \"\" \n",
    "in_json                 = \"/workspace/fine_tune/meta_lat.json\"\n",
    "\n",
    "# SDXL CONFIG\n",
    "grad_checkpointing      = True\n",
    "no_half_vae             = True \n",
    "cache_text_encoder_outputs = True\n",
    "min_timestep            = 0 \n",
    "max_timestep            = 1000\n",
    "\n",
    "# DATASET CONFIG\n",
    "num_repeats             = 1\n",
    "resolution              = 1024\n",
    "keep_tokens             = 0\n",
    "\n",
    "# GENERAL CONFIG\n",
    "max_train_steps         = 2500\n",
    "train_batch_size        = 1 \n",
    "mixed_precision         = \"fp16\"\n",
    "seed                    = -1\n",
    "\n",
    "# SAVE OUTPUT AS\n",
    "save_precision          = \"fp16\" \n",
    "save_every_n_steps      = 1000\n",
    "save_optimizer_state    = False \n",
    "save_model_as           = \"safetensors\"\n",
    "\n",
    "# SAMPLE PROMPT\n",
    "prompt                  = \"1girl, aqua eyes, baseball cap, blonde hair, closed mouth, earrings, green background, hat, hoop earrings, jewelry, looking at viewer, shirt, short hair, simple background, solo, upper body, yellow shirt\"\n",
    "custom_negative_prompt  = \"3d render, smooth, plastic, blurry, grainy, low-resolution, deep-fried, oversaturated\"\n",
    "sample_interval         = 100 \n",
    "\n",
    "# It generates black images if fp16\n",
    "if mixed_precision == \"fp16:\n",
    "    sample_interval = 9999999\n",
    "sampler                 = \"euler_a\" \n",
    "logging_dir             = os.path.join(training_dir, \"logs\")\n",
    "\n",
    "os.chdir(repo_dir)\n",
    "\n",
    "prompt_config = {\n",
    "    \"prompt\": {\n",
    "        \"negative_prompt\" : negative_prompt if not custom_negative_prompt else custom_negative_prompt,\n",
    "        \"width\"           : resolution,\n",
    "        \"height\"          : resolution,\n",
    "        \"scale\"           : 7,\n",
    "        \"sample_steps\"    : 28,\n",
    "        \"subset\"          : [\n",
    "            {\n",
    "                \"prompt\" : prompt,\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "}\n",
    "\n",
    "train_config = {\n",
    "    \"sdxl_arguments\": {\n",
    "        \"cache_text_encoder_outputs\" : cache_text_encoder_outputs,\n",
    "        \"no_half_vae\"                : no_half_vae,\n",
    "        \"min_timestep\"               : min_timestep,\n",
    "        \"max_timestep\"               : max_timestep,\n",
    "        \"shuffle_caption\"            : True if not cache_text_encoder_outputs else False,\n",
    "    },\n",
    "    \"model_arguments\": {\n",
    "        \"pretrained_model_name_or_path\" : model_path,\n",
    "        \"vae\"                           : vae_path,\n",
    "    },\n",
    "    \"dataset_arguments\": {\n",
    "        \"debug_dataset\"                 : False,\n",
    "        \"in_json\"                       : in_json,\n",
    "        \"train_data_dir\"                : train_data_dir,\n",
    "        \"dataset_repeats\"               : num_repeats,\n",
    "        \"keep_tokens\"                   : keep_tokens,\n",
    "        \"resolution\"                    : str(resolution) + ',' + str(resolution),\n",
    "        \"caption_dropout_rate\"          : 0,\n",
    "        \"caption_tag_dropout_rate\"      : 0,\n",
    "        \"caption_dropout_every_n_epochs\": 0,\n",
    "        \"color_aug\"                     : False,\n",
    "        \"face_crop_aug_range\"           : None,\n",
    "        \"token_warmup_min\"              : 1,\n",
    "        \"token_warmup_step\"             : 0,\n",
    "    },\n",
    "    \"training_arguments\": {\n",
    "        \"output_dir\"                    : output_dir,\n",
    "        \"output_name\"                   : project_name if project_name else \"last\",\n",
    "        \"save_precision\"                : save_precision,\n",
    "        \"save_every_n_steps\"            : save_every_n_steps,\n",
    "        \"save_n_epoch_ratio\"            : None,\n",
    "        \"save_last_n_epochs\"            : None,\n",
    "        \"save_state\"                    : None,\n",
    "        \"save_last_n_epochs_state\"      : None,\n",
    "        \"resume\"                        : None,\n",
    "        \"train_batch_size\"              : train_batch_size,\n",
    "        \"max_token_length\"              : 225,\n",
    "        \"mem_eff_attn\"                  : False,\n",
    "        \"xformers\"                      : True,\n",
    "        \"max_train_steps\"               : max_train_steps,\n",
    "        \"max_data_loader_n_workers\"     : 8,\n",
    "        \"persistent_data_loader_workers\": True,\n",
    "        \"seed\"                          : seed if seed > 0 else None,\n",
    "        \"gradient_checkpointing\"        : grad_checkpointing,\n",
    "        \"gradient_accumulation_steps\"   : 1,\n",
    "        \"mixed_precision\"               : mixed_precision,\n",
    "    },\n",
    "    \"logging_arguments\": {\n",
    "        \"log_with\"          : \"wandb\" if wandb_api_key else \"tensorboard\",\n",
    "        \"log_tracker_name\"  : project_name if wandb_api_key and not project_name == \"last\" else None,\n",
    "        \"logging_dir\"       : logging_dir,\n",
    "        \"log_prefix\"        : project_name if not wandb_api_key else None,\n",
    "    },\n",
    "    \"sample_prompt_arguments\": {\n",
    "        \"sample_every_n_steps\"    : sample_interval,\n",
    "        \"sample_every_n_epochs\"   : None,\n",
    "        \"sample_sampler\"          : sampler,\n",
    "    },\n",
    "    \"saving_arguments\": {\n",
    "        \"save_model_as\": \"safetensors\"\n",
    "    },\n",
    "}\n",
    "\n",
    "def write_file(filename, contents):\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(contents)\n",
    "\n",
    "def eliminate_none_variable(config):\n",
    "    for key in config:\n",
    "        if isinstance(config[key], dict):\n",
    "            for sub_key in config[key]:\n",
    "                if config[key][sub_key] == \"\":\n",
    "                    config[key][sub_key] = None\n",
    "        elif config[key] == \"\":\n",
    "            config[key] = None\n",
    "\n",
    "    return config\n",
    "\n",
    "try:\n",
    "    train_config.update(optimizer_config)\n",
    "except NameError:\n",
    "    raise NameError(\"'optimizer_config' dictionary is missing. Please run  'Optimizer Config' cell.\")\n",
    "\n",
    "advanced_training_warning = False\n",
    "try:\n",
    "    train_config.update(advanced_training_config)\n",
    "except NameError:\n",
    "    advanced_training_warning = True\n",
    "    pass\n",
    "\n",
    "deployment_config_warning = False\n",
    "try:\n",
    "    train_config.update(deployment_config)\n",
    "except NameError:\n",
    "    deployment_config_warning = True\n",
    "    pass\n",
    "\n",
    "config_path         = os.path.join(config_dir, \"config_file.toml\")\n",
    "prompt_path         = os.path.join(config_dir, \"sample_prompt.toml\")\n",
    "\n",
    "config_str          = toml.dumps(eliminate_none_variable(train_config))\n",
    "prompt_str          = toml.dumps(eliminate_none_variable(prompt_config))\n",
    "\n",
    "write_file(config_path, config_str)\n",
    "write_file(prompt_path, prompt_str)\n",
    "\n",
    "print(config_str)\n",
    "\n",
    "if advanced_training_warning:\n",
    "    import textwrap\n",
    "    error_message = \"WARNING: This is not an error message, but the [advanced_training_config] dictionary is missing. Please run the 'Advanced Training Config' cell if you intend to use it, or continue to the next step.\"\n",
    "    wrapped_message = textwrap.fill(error_message, width=80)\n",
    "    print('\\033[38;2;204;102;102m' + wrapped_message + '\\033[0m\\n')\n",
    "    pass\n",
    "    \n",
    "if deployment_config_warning:\n",
    "    import textwrap\n",
    "    error_message = \"WARNING: This is not an error message, but the [deployment_config] dictionary is missing. Please run the 'Deployment Training Config' cell if you intend to use it, or continue to the next step.\"\n",
    "    wrapped_message = textwrap.fill(error_message, width=80)\n",
    "    print('\\033[38;2;204;102;102m' + wrapped_message + '\\033[0m\\n')\n",
    "    pass\n",
    "\n",
    "print(prompt_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0842452e-f924-4600-8d6b-517298f632c5",
   "metadata": {},
   "source": [
    "# Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2740ef-14a6-4d93-8fc2-2a51cbb7446c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6224.35s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading settings from /workspace/fine_tune/config/config_file.toml...\n",
      "/workspace/fine_tune/config/config_file\n",
      "noise_offset is set to 0.0357 / noise_offsetが0.0357に設定されました\n",
      "prepare tokenizers\n",
      "update token length: 225\n",
      "Training with captions.\n",
      "loading existing metadata: /workspace/fine_tune/meta_lat.json\n",
      "metadata has bucket info, enable bucketing / メタデータにbucket情報があるためbucketを有効にします\n",
      "using bucket info in metadata / メタデータ内のbucket情報を使います\n",
      "[Dataset 0]\n",
      "  batch_size: 1\n",
      "  resolution: (1024, 1024)\n",
      "  enable_bucket: True\n",
      "  min_bucket_reso: None\n",
      "  max_bucket_reso: None\n",
      "  bucket_reso_steps: None\n",
      "  bucket_no_upscale: None\n",
      "\n",
      "  [Subset 0 of Dataset 0]\n",
      "    image_dir: \"/workspace/fine_tune/train_data\"\n",
      "    image_count: 98\n",
      "    num_repeats: 1\n",
      "    shuffle_caption: False\n",
      "    keep_tokens: 0\n",
      "    caption_dropout_rate: 0\n",
      "    caption_dropout_every_n_epoches: 0\n",
      "    caption_tag_dropout_rate: 0\n",
      "    color_aug: False\n",
      "    flip_aug: False\n",
      "    face_crop_aug_range: None\n",
      "    random_crop: False\n",
      "    token_warmup_min: 1,\n",
      "    token_warmup_step: 0,\n",
      "    metadata_file: /workspace/fine_tune/meta_lat.json\n",
      "\n",
      "\n",
      "[Dataset 0]\n",
      "loading image sizes.\n",
      "100%|███████████████████████████████████████| 98/98 [00:00<00:00, 241363.35it/s]\n",
      "make buckets\n",
      "number of images (including repeats) / 各bucketの画像枚数（繰り返し回数を含む）\n",
      "bucket 0: resolution (576, 1024), count: 1\n",
      "bucket 1: resolution (640, 1024), count: 2\n",
      "bucket 2: resolution (704, 1024), count: 10\n",
      "bucket 3: resolution (768, 1024), count: 24\n",
      "bucket 4: resolution (832, 1024), count: 14\n",
      "bucket 5: resolution (896, 1024), count: 14\n",
      "bucket 6: resolution (960, 1024), count: 8\n",
      "bucket 7: resolution (1024, 576), count: 1\n",
      "bucket 8: resolution (1024, 640), count: 8\n",
      "bucket 9: resolution (1024, 704), count: 6\n",
      "bucket 10: resolution (1024, 768), count: 4\n",
      "bucket 11: resolution (1024, 832), count: 1\n",
      "bucket 12: resolution (1024, 896), count: 3\n",
      "bucket 13: resolution (1024, 1024), count: 2\n",
      "mean ar error (without repeats): 0.0\n",
      "prepare accelerator\n",
      "loading model for process 0/1\n",
      "load StableDiffusion checkpoint: /workspace/pretrained_model/sd_xl_base_0.9.safetensors\n",
      "building U-Net\n",
      "loading U-Net from checkpoint\n",
      "U-Net:  <All keys matched successfully>\n",
      "building text encoders\n",
      "loading text encoders from checkpoint\n",
      "text encoder 1: <All keys matched successfully>\n",
      "text encoder2: <All keys matched successfully>\n",
      "building VAE\n",
      "loading VAE from checkpoint\n",
      "VAE: <All keys matched successfully>\n",
      "load VAE: /workspace/vae/sdxl_vae.safetensors\n",
      "additional VAE loaded\n",
      "Disable Diffusers' xformers\n",
      "Enable xformers for U-Net\n",
      "number of models: 1\n",
      "number of trainable parameters: 2567463684\n",
      "prepare optimizer, data loader etc.\n",
      "use Adafactor optimizer | {'scale_parameter': False, 'relative_step': False, 'warmup_init': False}\n",
      "because max_grad_norm is set, clip_grad_norm is enabled. consider set to 0 / max_grad_normが設定されているためclip_grad_normが有効になります。0に設定して無効にしたほうがいいかもしれません\n",
      "caching text encoder outputs\n",
      "100%|███████████████████████████████████████████| 98/98 [00:10<00:00,  9.39it/s]\n",
      "running training / 学習開始\n",
      "  num examples / サンプル数: 98\n",
      "  num batches per epoch / 1epochのバッチ数: 98\n",
      "  num epochs / epoch数: 26\n",
      "  batch size per device / バッチサイズ: 1\n",
      "  total train batch size (with parallel & distributed & accumulation) / 総バッチサイズ（並列学習、勾配合計含む）: 1\n",
      "  gradient accumulation steps / 勾配を合計するステップ数 = 1\n",
      "  total optimization steps / 学習ステップ数: 2500\n",
      "steps:   0%|                                           | 0/2500 [00:00<?, ?it/s]\n",
      "epoch 1/26\n",
      "steps:   4%|▉                      | 98/2500 [02:21<57:43,  1.44s/it, loss=0.13]\n",
      "epoch 2/26\n",
      "steps:   4%|▊                    | 100/2500 [02:24<57:38,  1.44s/it, loss=0.186]\n",
      "generating sample images at step / サンプル画像生成 ステップ: 100\n",
      "prompt: 1girl, aqua eyes, baseball cap, blonde hair, closed mouth, earrings, green background, hat, hoop earrings, jewelry, looking at viewer, shirt, short hair, simple background, solo, upper body, yellow shirt\n",
      "negative_prompt: 3d render, smooth, plastic, blurry, grainy, low-resolution, deep-fried, oversaturated\n",
      "height: 1024\n",
      "width: 1024\n",
      "sample_steps: 28\n",
      "scale: 7\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|█▌                                          | 1/28 [00:00<00:11,  2.27it/s]\u001b[A\n",
      "  7%|███▏                                        | 2/28 [00:00<00:09,  2.88it/s]\u001b[A\n",
      " 11%|████▋                                       | 3/28 [00:01<00:07,  3.14it/s]\u001b[A\n",
      " 14%|██████▎                                     | 4/28 [00:01<00:07,  3.28it/s]\u001b[A\n",
      " 18%|███████▊                                    | 5/28 [00:01<00:06,  3.35it/s]\u001b[A\n",
      " 21%|█████████▍                                  | 6/28 [00:01<00:06,  3.40it/s]\u001b[A\n",
      " 25%|███████████                                 | 7/28 [00:02<00:06,  3.44it/s]\u001b[A\n",
      " 29%|████████████▌                               | 8/28 [00:02<00:05,  3.46it/s]\u001b[A\n",
      " 32%|██████████████▏                             | 9/28 [00:02<00:05,  3.48it/s]\u001b[A\n",
      " 36%|███████████████▎                           | 10/28 [00:03<00:05,  3.48it/s]\u001b[A\n",
      " 39%|████████████████▉                          | 11/28 [00:03<00:04,  3.49it/s]\u001b[A\n",
      " 43%|██████████████████▍                        | 12/28 [00:03<00:04,  3.50it/s]\u001b[A\n",
      " 46%|███████████████████▉                       | 13/28 [00:03<00:04,  3.50it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 14/28 [00:04<00:04,  3.46it/s]\u001b[A\n",
      " 54%|███████████████████████                    | 15/28 [00:04<00:03,  3.47it/s]\u001b[A\n",
      " 57%|████████████████████████▌                  | 16/28 [00:04<00:03,  3.48it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 17/28 [00:05<00:03,  3.48it/s]\u001b[A\n",
      " 64%|███████████████████████████▋               | 18/28 [00:05<00:02,  3.49it/s]\u001b[A\n",
      " 68%|█████████████████████████████▏             | 19/28 [00:05<00:02,  3.49it/s]\u001b[A\n",
      " 71%|██████████████████████████████▋            | 20/28 [00:05<00:02,  3.50it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 21/28 [00:06<00:02,  3.50it/s]\u001b[A\n",
      " 79%|█████████████████████████████████▊         | 22/28 [00:06<00:01,  3.50it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 23/28 [00:06<00:01,  3.50it/s]\u001b[A\n",
      " 86%|████████████████████████████████████▊      | 24/28 [00:07<00:01,  3.50it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▍    | 25/28 [00:07<00:00,  3.50it/s]\u001b[A\n",
      " 93%|███████████████████████████████████████▉   | 26/28 [00:07<00:00,  3.50it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████▍ | 27/28 [00:07<00:00,  3.50it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 28/28 [00:08<00:00,  3.49it/s]\u001b[A\n",
      "steps:   8%|█▋                   | 196/2500 [04:52<57:13,  1.49s/it, loss=0.128]\u001b[A\n",
      "epoch 3/26\n",
      "steps:   8%|█▋                   | 200/2500 [04:57<57:02,  1.49s/it, loss=0.232]\n",
      "generating sample images at step / サンプル画像生成 ステップ: 200\n",
      "prompt: 1girl, aqua eyes, baseball cap, blonde hair, closed mouth, earrings, green background, hat, hoop earrings, jewelry, looking at viewer, shirt, short hair, simple background, solo, upper body, yellow shirt\n",
      "negative_prompt: 3d render, smooth, plastic, blurry, grainy, low-resolution, deep-fried, oversaturated\n",
      "height: 1024\n",
      "width: 1024\n",
      "sample_steps: 28\n",
      "scale: 7\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|█▌                                          | 1/28 [00:00<00:08,  3.26it/s]\u001b[A\n",
      "  7%|███▏                                        | 2/28 [00:00<00:07,  3.41it/s]\u001b[A\n",
      " 11%|████▋                                       | 3/28 [00:00<00:07,  3.45it/s]\u001b[A\n",
      " 14%|██████▎                                     | 4/28 [00:01<00:06,  3.47it/s]\u001b[A\n",
      " 18%|███████▊                                    | 5/28 [00:01<00:06,  3.49it/s]\u001b[A\n",
      " 21%|█████████▍                                  | 6/28 [00:01<00:06,  3.49it/s]\u001b[A\n",
      " 25%|███████████                                 | 7/28 [00:02<00:06,  3.50it/s]\u001b[A\n",
      " 29%|████████████▌                               | 8/28 [00:02<00:05,  3.50it/s]\u001b[A\n",
      " 32%|██████████████▏                             | 9/28 [00:02<00:05,  3.50it/s]\u001b[A\n",
      " 36%|███████████████▎                           | 10/28 [00:02<00:05,  3.50it/s]\u001b[A\n",
      " 39%|████████████████▉                          | 11/28 [00:03<00:04,  3.50it/s]\u001b[A\n",
      " 43%|██████████████████▍                        | 12/28 [00:03<00:04,  3.50it/s]\u001b[A\n",
      " 46%|███████████████████▉                       | 13/28 [00:03<00:04,  3.50it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 14/28 [00:04<00:04,  3.50it/s]\u001b[A\n",
      " 54%|███████████████████████                    | 15/28 [00:04<00:03,  3.50it/s]\u001b[A\n",
      " 57%|████████████████████████▌                  | 16/28 [00:04<00:03,  3.49it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 17/28 [00:04<00:03,  3.49it/s]\u001b[A\n",
      " 64%|███████████████████████████▋               | 18/28 [00:05<00:02,  3.49it/s]\u001b[A\n",
      " 68%|█████████████████████████████▏             | 19/28 [00:05<00:02,  3.49it/s]\u001b[A\n",
      " 71%|██████████████████████████████▋            | 20/28 [00:05<00:02,  3.49it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 21/28 [00:06<00:02,  3.49it/s]\u001b[A\n",
      " 79%|█████████████████████████████████▊         | 22/28 [00:06<00:01,  3.49it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 23/28 [00:06<00:01,  3.49it/s]\u001b[A\n",
      " 86%|████████████████████████████████████▊      | 24/28 [00:06<00:01,  3.49it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▍    | 25/28 [00:07<00:00,  3.49it/s]\u001b[A\n",
      " 93%|███████████████████████████████████████▉   | 26/28 [00:07<00:00,  3.49it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████▍ | 27/28 [00:07<00:00,  3.49it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 28/28 [00:08<00:00,  3.49it/s]\u001b[A\n",
      "steps:  12%|██▍                  | 294/2500 [07:22<55:16,  1.50s/it, loss=0.145]\u001b[A\n",
      "epoch 4/26\n",
      "steps:  12%|██▍                 | 300/2500 [07:30<55:01,  1.50s/it, loss=0.0815]\n",
      "generating sample images at step / サンプル画像生成 ステップ: 300\n",
      "prompt: 1girl, aqua eyes, baseball cap, blonde hair, closed mouth, earrings, green background, hat, hoop earrings, jewelry, looking at viewer, shirt, short hair, simple background, solo, upper body, yellow shirt\n",
      "negative_prompt: 3d render, smooth, plastic, blurry, grainy, low-resolution, deep-fried, oversaturated\n",
      "height: 1024\n",
      "width: 1024\n",
      "sample_steps: 28\n",
      "scale: 7\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|█▌                                          | 1/28 [00:00<00:08,  3.23it/s]\u001b[A\n",
      "  7%|███▏                                        | 2/28 [00:00<00:07,  3.39it/s]\u001b[A\n",
      " 11%|████▋                                       | 3/28 [00:00<00:07,  3.44it/s]\u001b[A\n",
      " 14%|██████▎                                     | 4/28 [00:01<00:06,  3.47it/s]\u001b[A\n",
      " 18%|███████▊                                    | 5/28 [00:01<00:06,  3.48it/s]\u001b[A\n",
      " 21%|█████████▍                                  | 6/28 [00:01<00:06,  3.49it/s]\u001b[A\n",
      " 25%|███████████                                 | 7/28 [00:02<00:06,  3.49it/s]\u001b[A\n",
      " 29%|████████████▌                               | 8/28 [00:02<00:05,  3.49it/s]\u001b[A\n",
      " 32%|██████████████▏                             | 9/28 [00:02<00:05,  3.49it/s]\u001b[A\n",
      " 36%|███████████████▎                           | 10/28 [00:02<00:05,  3.49it/s]\u001b[A\n",
      " 39%|████████████████▉                          | 11/28 [00:03<00:04,  3.49it/s]\u001b[A\n",
      " 43%|██████████████████▍                        | 12/28 [00:03<00:04,  3.49it/s]\u001b[A\n",
      " 46%|███████████████████▉                       | 13/28 [00:03<00:04,  3.46it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 14/28 [00:04<00:04,  3.43it/s]\u001b[A\n",
      " 54%|███████████████████████                    | 15/28 [00:04<00:03,  3.44it/s]\u001b[A\n",
      " 57%|████████████████████████▌                  | 16/28 [00:04<00:03,  3.46it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 17/28 [00:04<00:03,  3.47it/s]\u001b[A\n",
      " 64%|███████████████████████████▋               | 18/28 [00:05<00:02,  3.47it/s]\u001b[A\n",
      " 68%|█████████████████████████████▏             | 19/28 [00:05<00:02,  3.48it/s]\u001b[A\n",
      " 71%|██████████████████████████████▋            | 20/28 [00:05<00:02,  3.48it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 21/28 [00:06<00:02,  3.47it/s]\u001b[A\n",
      " 79%|█████████████████████████████████▊         | 22/28 [00:06<00:01,  3.48it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 23/28 [00:06<00:01,  3.48it/s]\u001b[A\n",
      " 86%|████████████████████████████████████▊      | 24/28 [00:06<00:01,  3.48it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▍    | 25/28 [00:07<00:00,  3.48it/s]\u001b[A\n",
      " 93%|███████████████████████████████████████▉   | 26/28 [00:07<00:00,  3.48it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████▍ | 27/28 [00:07<00:00,  3.48it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 28/28 [00:08<00:00,  3.49it/s]\u001b[A\n",
      "steps:  16%|███▎                 | 392/2500 [09:51<52:59,  1.51s/it, loss=0.122]\u001b[A\n",
      "epoch 5/26\n",
      "steps:  16%|███▎                 | 400/2500 [10:01<52:38,  1.50s/it, loss=0.123]\n",
      "generating sample images at step / サンプル画像生成 ステップ: 400\n",
      "prompt: 1girl, aqua eyes, baseball cap, blonde hair, closed mouth, earrings, green background, hat, hoop earrings, jewelry, looking at viewer, shirt, short hair, simple background, solo, upper body, yellow shirt\n",
      "negative_prompt: 3d render, smooth, plastic, blurry, grainy, low-resolution, deep-fried, oversaturated\n",
      "height: 1024\n",
      "width: 1024\n",
      "sample_steps: 28\n",
      "scale: 7\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|█▌                                          | 1/28 [00:00<00:09,  2.84it/s]\u001b[A\n",
      "  7%|███▏                                        | 2/28 [00:00<00:08,  3.21it/s]\u001b[A\n",
      " 11%|████▋                                       | 3/28 [00:00<00:07,  3.33it/s]\u001b[A\n",
      " 14%|██████▎                                     | 4/28 [00:01<00:07,  3.39it/s]\u001b[A\n",
      " 18%|███████▊                                    | 5/28 [00:01<00:06,  3.38it/s]\u001b[A\n",
      " 21%|█████████▍                                  | 6/28 [00:01<00:06,  3.41it/s]\u001b[A\n",
      " 25%|███████████                                 | 7/28 [00:02<00:06,  3.43it/s]\u001b[A\n",
      " 29%|████████████▌                               | 8/28 [00:02<00:05,  3.45it/s]\u001b[A\n",
      " 32%|██████████████▏                             | 9/28 [00:02<00:05,  3.46it/s]\u001b[A\n",
      " 36%|███████████████▎                           | 10/28 [00:02<00:05,  3.47it/s]\u001b[A\n",
      " 39%|████████████████▉                          | 11/28 [00:03<00:04,  3.48it/s]\u001b[A\n",
      " 43%|██████████████████▍                        | 12/28 [00:03<00:04,  3.48it/s]\u001b[A\n",
      " 46%|███████████████████▉                       | 13/28 [00:03<00:04,  3.48it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 14/28 [00:04<00:04,  3.48it/s]\u001b[A\n",
      " 54%|███████████████████████                    | 15/28 [00:04<00:03,  3.49it/s]\u001b[A\n",
      " 57%|████████████████████████▌                  | 16/28 [00:04<00:03,  3.48it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 17/28 [00:04<00:03,  3.49it/s]\u001b[A\n",
      " 64%|███████████████████████████▋               | 18/28 [00:05<00:02,  3.49it/s]\u001b[A\n",
      " 68%|█████████████████████████████▏             | 19/28 [00:05<00:02,  3.49it/s]\u001b[A\n",
      " 71%|██████████████████████████████▋            | 20/28 [00:05<00:02,  3.48it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 21/28 [00:06<00:02,  3.48it/s]\u001b[A\n",
      " 79%|█████████████████████████████████▊         | 22/28 [00:06<00:01,  3.48it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 23/28 [00:06<00:01,  3.49it/s]\u001b[A\n",
      " 86%|████████████████████████████████████▊      | 24/28 [00:06<00:01,  3.48it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▍    | 25/28 [00:07<00:00,  3.48it/s]\u001b[A\n",
      " 93%|███████████████████████████████████████▉   | 26/28 [00:07<00:00,  3.48it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████▍ | 27/28 [00:07<00:00,  3.48it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 28/28 [00:08<00:00,  3.48it/s]\u001b[A\n",
      "steps:  20%|████▎                 | 490/2500 [12:16<50:20,  1.50s/it, loss=0.13]\u001b[A\n",
      "epoch 6/26\n",
      "steps:  20%|████                | 500/2500 [12:29<49:58,  1.50s/it, loss=0.0914]\n",
      "generating sample images at step / サンプル画像生成 ステップ: 500\n",
      "prompt: 1girl, aqua eyes, baseball cap, blonde hair, closed mouth, earrings, green background, hat, hoop earrings, jewelry, looking at viewer, shirt, short hair, simple background, solo, upper body, yellow shirt\n",
      "negative_prompt: 3d render, smooth, plastic, blurry, grainy, low-resolution, deep-fried, oversaturated\n",
      "height: 1024\n",
      "width: 1024\n",
      "sample_steps: 28\n",
      "scale: 7\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|█▌                                          | 1/28 [00:00<00:08,  3.25it/s]\u001b[A\n",
      "  7%|███▏                                        | 2/28 [00:00<00:07,  3.40it/s]\u001b[A\n",
      " 11%|████▋                                       | 3/28 [00:00<00:07,  3.25it/s]\u001b[A\n",
      " 14%|██████▎                                     | 4/28 [00:01<00:07,  3.35it/s]\u001b[A\n",
      " 18%|███████▊                                    | 5/28 [00:01<00:06,  3.41it/s]\u001b[A\n",
      " 21%|█████████▍                                  | 6/28 [00:01<00:06,  3.43it/s]\u001b[A\n",
      " 25%|███████████                                 | 7/28 [00:02<00:06,  3.45it/s]\u001b[A\n",
      " 29%|████████████▌                               | 8/28 [00:02<00:05,  3.47it/s]\u001b[A\n",
      " 32%|██████████████▏                             | 9/28 [00:02<00:05,  3.47it/s]\u001b[A\n",
      " 36%|███████████████▎                           | 10/28 [00:02<00:05,  3.48it/s]\u001b[A\n",
      " 39%|████████████████▉                          | 11/28 [00:03<00:04,  3.48it/s]\u001b[A\n",
      " 43%|██████████████████▍                        | 12/28 [00:03<00:04,  3.49it/s]\u001b[A\n",
      " 46%|███████████████████▉                       | 13/28 [00:03<00:04,  3.48it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 14/28 [00:04<00:04,  3.49it/s]\u001b[A\n",
      " 54%|███████████████████████                    | 15/28 [00:04<00:03,  3.49it/s]\u001b[A\n",
      " 57%|████████████████████████▌                  | 16/28 [00:04<00:03,  3.48it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 17/28 [00:04<00:03,  3.49it/s]\u001b[A\n",
      " 64%|███████████████████████████▋               | 18/28 [00:05<00:02,  3.49it/s]\u001b[A\n",
      " 68%|█████████████████████████████▏             | 19/28 [00:05<00:02,  3.49it/s]\u001b[A\n",
      " 71%|██████████████████████████████▋            | 20/28 [00:05<00:02,  3.49it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 21/28 [00:06<00:02,  3.49it/s]\u001b[A\n",
      " 79%|█████████████████████████████████▊         | 22/28 [00:06<00:01,  3.49it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 23/28 [00:06<00:01,  3.49it/s]\u001b[A\n",
      " 86%|████████████████████████████████████▊      | 24/28 [00:06<00:01,  3.49it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▍    | 25/28 [00:07<00:00,  3.49it/s]\u001b[A\n",
      " 93%|███████████████████████████████████████▉   | 26/28 [00:07<00:00,  3.49it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████▍ | 27/28 [00:07<00:00,  3.49it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 28/28 [00:08<00:00,  3.48it/s]\u001b[A\n",
      "steps:  24%|████▉                | 588/2500 [14:44<47:54,  1.50s/it, loss=0.107]\u001b[A\n",
      "epoch 7/26\n",
      "steps:  24%|█████                | 600/2500 [14:59<47:29,  1.50s/it, loss=0.143]\n",
      "generating sample images at step / サンプル画像生成 ステップ: 600\n",
      "prompt: 1girl, aqua eyes, baseball cap, blonde hair, closed mouth, earrings, green background, hat, hoop earrings, jewelry, looking at viewer, shirt, short hair, simple background, solo, upper body, yellow shirt\n",
      "negative_prompt: 3d render, smooth, plastic, blurry, grainy, low-resolution, deep-fried, oversaturated\n",
      "height: 1024\n",
      "width: 1024\n",
      "sample_steps: 28\n",
      "scale: 7\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|█▌                                          | 1/28 [00:00<00:16,  1.65it/s]\u001b[A\n",
      "  7%|███▏                                        | 2/28 [00:00<00:10,  2.39it/s]\u001b[A\n",
      " 11%|████▋                                       | 3/28 [00:01<00:08,  2.78it/s]\u001b[A\n",
      " 14%|██████▎                                     | 4/28 [00:01<00:07,  3.01it/s]\u001b[A\n",
      " 18%|███████▊                                    | 5/28 [00:01<00:07,  3.16it/s]\u001b[A\n",
      " 21%|█████████▍                                  | 6/28 [00:02<00:06,  3.25it/s]\u001b[A\n",
      " 25%|███████████                                 | 7/28 [00:02<00:06,  3.32it/s]\u001b[A\n",
      " 29%|████████████▌                               | 8/28 [00:02<00:05,  3.35it/s]\u001b[A\n",
      " 32%|██████████████▏                             | 9/28 [00:02<00:05,  3.37it/s]\u001b[A\n",
      " 36%|███████████████▎                           | 10/28 [00:03<00:05,  3.40it/s]\u001b[A\n",
      " 39%|████████████████▉                          | 11/28 [00:03<00:04,  3.42it/s]\u001b[A\n",
      " 43%|██████████████████▍                        | 12/28 [00:03<00:04,  3.42it/s]\u001b[A\n",
      " 46%|███████████████████▉                       | 13/28 [00:04<00:04,  3.43it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 14/28 [00:04<00:04,  3.44it/s]\u001b[A\n",
      " 54%|███████████████████████                    | 15/28 [00:04<00:03,  3.44it/s]\u001b[A\n",
      " 57%|████████████████████████▌                  | 16/28 [00:04<00:03,  3.45it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 17/28 [00:05<00:03,  3.45it/s]\u001b[A\n",
      " 64%|███████████████████████████▋               | 18/28 [00:05<00:02,  3.45it/s]\u001b[A\n",
      " 68%|█████████████████████████████▏             | 19/28 [00:05<00:02,  3.45it/s]\u001b[A\n",
      " 71%|██████████████████████████████▋            | 20/28 [00:06<00:02,  3.45it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 21/28 [00:06<00:02,  3.46it/s]\u001b[A\n",
      " 79%|█████████████████████████████████▊         | 22/28 [00:06<00:01,  3.47it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 23/28 [00:06<00:01,  3.47it/s]\u001b[A\n",
      " 86%|████████████████████████████████████▊      | 24/28 [00:07<00:01,  3.47it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▍    | 25/28 [00:07<00:00,  3.48it/s]\u001b[A\n",
      " 93%|███████████████████████████████████████▉   | 26/28 [00:07<00:00,  3.48it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████▍ | 27/28 [00:08<00:00,  3.48it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 28/28 [00:08<00:00,  3.48it/s]\u001b[A\n",
      "steps:  27%|█████▊               | 686/2500 [17:12<45:29,  1.50s/it, loss=0.115]\u001b[A\n",
      "epoch 8/26\n",
      "steps:  28%|█████▌              | 700/2500 [17:30<45:01,  1.50s/it, loss=0.0764]\n",
      "generating sample images at step / サンプル画像生成 ステップ: 700\n",
      "prompt: 1girl, aqua eyes, baseball cap, blonde hair, closed mouth, earrings, green background, hat, hoop earrings, jewelry, looking at viewer, shirt, short hair, simple background, solo, upper body, yellow shirt\n",
      "negative_prompt: 3d render, smooth, plastic, blurry, grainy, low-resolution, deep-fried, oversaturated\n",
      "height: 1024\n",
      "width: 1024\n",
      "sample_steps: 28\n",
      "scale: 7\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|█▌                                          | 1/28 [00:00<00:08,  3.25it/s]\u001b[A\n",
      "  7%|███▏                                        | 2/28 [00:00<00:07,  3.40it/s]\u001b[A\n",
      " 11%|████▋                                       | 3/28 [00:00<00:07,  3.45it/s]\u001b[A\n",
      " 14%|██████▎                                     | 4/28 [00:01<00:06,  3.47it/s]\u001b[A\n",
      " 18%|███████▊                                    | 5/28 [00:01<00:06,  3.49it/s]\u001b[A\n",
      " 21%|█████████▍                                  | 6/28 [00:01<00:06,  3.49it/s]\u001b[A\n",
      " 25%|███████████                                 | 7/28 [00:02<00:06,  3.49it/s]\u001b[A\n",
      " 29%|████████████▌                               | 8/28 [00:02<00:05,  3.49it/s]\u001b[A\n",
      " 32%|██████████████▏                             | 9/28 [00:02<00:05,  3.50it/s]\u001b[A\n",
      " 36%|███████████████▎                           | 10/28 [00:02<00:05,  3.50it/s]\u001b[A\n",
      " 39%|████████████████▉                          | 11/28 [00:03<00:04,  3.50it/s]\u001b[A\n",
      " 43%|██████████████████▍                        | 12/28 [00:03<00:04,  3.50it/s]\u001b[A\n",
      " 46%|███████████████████▉                       | 13/28 [00:03<00:04,  3.50it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 14/28 [00:04<00:03,  3.50it/s]\u001b[A\n",
      " 54%|███████████████████████                    | 15/28 [00:04<00:03,  3.50it/s]\u001b[A\n",
      " 57%|████████████████████████▌                  | 16/28 [00:04<00:03,  3.44it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 17/28 [00:04<00:03,  3.46it/s]\u001b[A\n",
      " 64%|███████████████████████████▋               | 18/28 [00:05<00:02,  3.47it/s]\u001b[A\n",
      " 68%|█████████████████████████████▏             | 19/28 [00:05<00:02,  3.47it/s]\u001b[A\n",
      " 71%|██████████████████████████████▋            | 20/28 [00:05<00:02,  3.48it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 21/28 [00:06<00:02,  3.49it/s]\u001b[A\n",
      " 79%|█████████████████████████████████▊         | 22/28 [00:06<00:01,  3.49it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 23/28 [00:06<00:01,  3.49it/s]\u001b[A\n",
      " 86%|████████████████████████████████████▊      | 24/28 [00:06<00:01,  3.49it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▍    | 25/28 [00:07<00:00,  3.48it/s]\u001b[A\n",
      " 93%|███████████████████████████████████████▉   | 26/28 [00:07<00:00,  3.48it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████▍ | 27/28 [00:07<00:00,  3.48it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 28/28 [00:08<00:00,  3.47it/s]\u001b[A\n",
      "steps:  30%|██████▏              | 741/2500 [18:44<44:28,  1.52s/it, loss=0.118]\u001b[A"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import toml\n",
    "\n",
    "sample_prompt   = \"/workspace/fine_tune/config/sample_prompt.toml\"\n",
    "config_file     = \"/workspace/fine_tune/config/config_file.toml\"\n",
    "\n",
    "def read_file(filename):\n",
    "    with open(filename, \"r\") as f:\n",
    "        contents = f.read()\n",
    "    return contents\n",
    "\n",
    "def train(config):\n",
    "    args = \"\"\n",
    "    for k, v in config.items():\n",
    "        if k.startswith(\"_\"):\n",
    "            args += f'\"{v}\" '\n",
    "        elif isinstance(v, str):\n",
    "            args += f'--{k}=\"{v}\" '\n",
    "        elif isinstance(v, bool) and v:\n",
    "            args += f\"--{k} \"\n",
    "        elif isinstance(v, float) and not isinstance(v, bool):\n",
    "            args += f\"--{k}={v} \"\n",
    "        elif isinstance(v, int) and not isinstance(v, bool):\n",
    "            args += f\"--{k}={v} \"\n",
    "\n",
    "    return args\n",
    "\n",
    "accelerate_conf = {\n",
    "    \"config_file\" : accelerate_config,\n",
    "    \"num_cpu_threads_per_process\" : 1,\n",
    "}\n",
    "\n",
    "train_conf = {\n",
    "    \"sample_prompts\"  : sample_prompt if os.path.exists(sample_prompt) else None,\n",
    "    \"config_file\"     : config_file,\n",
    "    \"wandb_api_key\"   : wandb_api_key if wandb_api_key else None,\n",
    "}\n",
    "\n",
    "accelerate_args = train(accelerate_conf)\n",
    "train_args = train(train_conf)\n",
    "\n",
    "final_args = f\"accelerate launch {accelerate_args} sdxl_train.py {train_args}\"\n",
    "\n",
    "os.chdir(repo_dir)\n",
    "!{final_args}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9736e6bc-f923-4e7a-b37a-0748659c2756",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3960b795-2a3e-4464-abe4-500e89a693ce",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(finetune_dir)\n",
    "\n",
    "ckpt_path = \"/workspace/pretrained_model/hitokomoru-xl-2500.ckpt\"\n",
    "# prompt = \"1girl, aqua eyes, baseball cap, blonde hair, closed mouth, earrings, green background, hat, hoop earrings, jewelry, looking at viewer, shirt, short hair, simple background, solo, upper body, yellow shirt\" \n",
    "# negative_prompt = \"lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry\" \n",
    "output_path = \"/workspace/tmp/\"\n",
    "interactive_mode = True\n",
    "\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "\n",
    "config = {\n",
    "    \"ckpt_path\"           : ckpt_path,\n",
    "    # \"prompt\"              : prompt,\n",
    "    \"output_dir\"          : output_path,\n",
    "    # \"negative_prompt\"     : negative_prompt,\n",
    "    \"interactive\"    : interactive_mode,\n",
    "}\n",
    "args = \"\"\n",
    "for k, v in config.items():\n",
    "    if k.startswith(\"_\"):\n",
    "        args += f'\"{v}\" '\n",
    "    elif isinstance(v, str):\n",
    "        args += f'--{k}=\"{v}\" '\n",
    "    elif isinstance(v, bool) and v:\n",
    "        args += f\"--{k} \"\n",
    "    elif isinstance(v, float) and not isinstance(v, bool):\n",
    "        args += f\"--{k}={v} \"\n",
    "    elif isinstance(v, int) and not isinstance(v, bool):\n",
    "        args += f\"--{k}={v} \"\n",
    "\n",
    "final_args = f\"python sdxl_minimal_inference.py {args}\"\n",
    "\n",
    "os.chdir(repo_dir)\n",
    "!{final_args}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
